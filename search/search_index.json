{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Documentaci\u00f3n Trabajo Final de Tr\u00e1fico La siguiente documentaci\u00f3n tiene como prop\u00f3sito exponer los conceptos que dan origen y sustento al trabajo final de Ger\u00f3nimo Passini y Lucas Gorordo para la asignatura \"Tr\u00e1fico\" de la carrera ingenier\u00eda de Telecomunicaciones. \u00bfEn qu\u00e9 se basa el proyecto? Antes de comenzar a dar detalles del proyecto, es importante tener en cuenta el concepto de Internet de las Cosas o tambi\u00e9n conocido como IoT, este se refiere a un gran n\u00famero de \u201ccosas\u201d u objetos que se conectan a Internet para que puedan compartir datos con otras cosas \u2013 aplicaciones para IoT, dispositivos conectados, m\u00e1quinas industriales y m\u00e1s. Los dispositivos conectados a Internet utilizan sensores integrados para reunir datos y, en algunos casos, realizar acciones con ellos. Los dispositivos y m\u00e1quinas conectados a Internet pueden mejorar nuestra forma de trabajar y de vivir. Algunos ejemplos reales de IoT van desde un hogar inteligente que ajusta autom\u00e1ticamente la calefacci\u00f3n y las luces hasta una f\u00e1brica inteligente que monitorea m\u00e1quinas industriales para buscar problemas y luego hace ajustes autom\u00e1ticos para evitar fallos. Los sistemas embebidos en este contexto son muy importantes, siempre y cuando est\u00e9n muy bien acompa\u00f1ados con una infraestructura de red que permita dar soporte a cientos de sensores y construir una aplicaci\u00f3n destinada al usuario final. En este sentido, es muy importante analizar el comportamiento de redes de sensores para una aplicaci\u00f3n en particular, en la que la cantidad de dispositivos inteligentes y su comportamiento juegan un rol fundamental. El presente trabajo tiene como finalidad poder crear un entorno de simulaci\u00f3n orientado a esquematizar una implementaci\u00f3n t\u00edpica, como suele suceder en el \u00e1rea de los sistemas embebidos, en b\u00fasqueda de poder realizar an\u00e1lisis de tr\u00e1fico en la etapa posterior a que ya se encuentre estable la etapa de adquisici\u00f3n de datos por los diversos sensores o perif\u00e9ricos que componen al proyecto. Estructura del proyecto Todo el material expuesto en esta instancia, ronda a partir de la siguiente estructura: Servicio a implementar Generador de trafico Adquisici\u00f3n de m\u00e9tricas Visualizaci\u00f3n de m\u00e9tricas La misma pretende ser implementada en Docker para crear un esquema de trabajo portable sobre el cual realizar pruebas de performance . Docker como estructura de trabajo Dada la estructura del trabajo a realizar, la tecnolog\u00eda que mejor se adapta a la modalidad de desarrollo es Docker \u00bfPor qu\u00e9? porque permite tener control sobre cada una de las fases de vida de un producto. Una aplicaci\u00f3n incluye no solo la aplicaci\u00f3n como tal, sino que tenemos un motor, un conjunto de librer\u00edas y el kernel o software. Docker permite agrupar todo esto en un contenedor y almacenarlo en nuestro disco duro. De forma que copia todo lo que pertenece a un mismo sistema operativo y lo almacena en una zona de nuestro disco duro para luego ejecutarla independientemente del sistema operativo. Esto permite que se pueda transportar la aplicaci\u00f3n y ejecutarla donde se desee, sin preocuparse por el software o si tienes todos los componentes de la aplicaci\u00f3n para iniciarla. La portabilidad es la gran caracter\u00edstica que permite una evoluci\u00f3n continua y r\u00e1pida en el desarrollo de un programa y es precisamente lo que se necesita en este momento para la realizaci\u00f3n de trabajos grupales de manera remota. A nivel general, \u00bfQu\u00e9 ventajas adicionales aporta esta tecnolog\u00eda al desarrollo de software? \u2192 Facilita el testing, facilita la tarea, puesto que si tenemos instalado Docker en nuestro ordenador y nos pasan un contenedor con una App a testear. Da igual cual sea el software que tengamos, docker nos permitir\u00e1 abrir la app y poder probarla. \u2192 Ahorra tiempo, al no obligarnos a instalar diferentes softwares para poder ejecutar una App. \u2192 Es muy sencillo crear y eliminar contenedores. \u2192 Son muy ligeros, lo que nos permite manejar diferentes contenedores dentro de una misma m\u00e1quina. \u2192 Es open source. \u2192 Nos proporcionan autonom\u00eda, a partir de que en cada contenedor tenemos todo lo necesario para ejecutar una aplicaci\u00f3n. \u2192 Portabilidad: Al almacenar los contenedores en discos duros, estos se pueden transportar de un lugar a otro sin problemas. \u2192 Im\u00e1genes Docker: Podr\u00edamos definir estas im\u00e1genes como sistemas operativos con aplicaciones instaladas. En este SO, podremos incluir nuestras im\u00e1genes para su posterior visualizaci\u00f3n en un equipo. \u2192 Repositorios Docker: \u201cBanco de im\u00e1genes docker\u201d creadas por usuarios a las cuales podemos tener acceso. \u2192 Con Docker, tenemos capacidad de ejecutar pr\u00e1cticamente todas las aplicaciones facilitando el compartir las aplicaciones a trav\u00e9s de los contenedores. \u2192 Se acelera el proceso de mantenimiento y desarrollo gracias a las facilidades para generar copias. \u2192 Las aplicaciones se ejecutan sin variaciones. Sin importar el equipo ni el ambiente. \u2192 Es un entorno seguro y no ofrece variaciones. \u00bfQu\u00e9 sistemas operativos admiten docker? Docker puede instalarse tanto en Linux como en Windows, pero es necesario agregar algunas particularidades al an\u00e1lisis. Con respecto a el mundo de Linux, Docker es una plataforma de c\u00f3digo abierto (en su mayor\u00eda) que funciona con cualquier distribuci\u00f3n de Linux de cualquier proveedor. En sus inicios, Docker no trabaj\u00f3 en estrecha colaboraci\u00f3n con ninguna empresa en particular en el espacio de Linux para desarrollar contenedores o hacer que funcionen con Linux. Pero no ocurre lo mismo con Windows, para este caso, Docker y Microsoft trabajaron en estrecha colaboraci\u00f3n para llevar contenedores a Windows. Esta diferencia puede ser importante para el usuario si se piensa en la longevidad o flexibilidad de los contenedores en Windows. Ya que, si Microsoft decidiera en el futuro dejar de admitir contenedores, probablemente ser\u00e1 el final de los contenedores en Windows. En Linux, estos riesgos no existen. Incluso si Docker decidiera detener el desarrollo, el ecosistema de contenedores ahora es tan din\u00e1mico y grande que otros proyectos de c\u00f3digo abierto probablemente tomar\u00edan el relevo y garantizar\u00edan que los contenedores de Linux sigan siendo viables. Para decirlo de otra manera: Se podr\u00e1 utilizar contenedores en Windows dentro de 10 a\u00f1os depende en gran medida de lo que Microsoft decida hacer. En Linux, es una apuesta mucho m\u00e1s segura que los contenedores seguir\u00e1n funcionando en una d\u00e9cada, independientemente de las elecciones que tome un proveedor en particular. Pese a esta independencia entre Linux y Docker, hay que destacar que la arquitectura de Docker es muy eficiente dentro de un sistema operativo Linux. \u00bfPero qu\u00e9 ocurre con Windows? El primer enfoque para admitir Docker en Windows fue Docker Toolbox, que es b\u00e1sicamente una m\u00e1quina virtual que utiliza Virtual Box con una imagen de Linux. Entonces, como sugiere el nombre, es solo una herramienta para aprender Docker, pero no es muy \u00fatil ya que es una VM normal. Con Windows 10 Pro, Microsoft present\u00f3 Hyper-V, que es una herramienta de virtualizaci\u00f3n s\u00faper r\u00e1pida, Docker para Windows se lanz\u00f3 para Windows 10 Pro, para ejecutar contenedores mucho m\u00e1s r\u00e1pido y m\u00e1s f\u00e1cil, pero en un principio se necesitaba Windows 10 \u201cPro\u201d, por lo que en \u201cHome\u201d no funcionaba. Cuando se lanz\u00f3 Windows Server 2016, fue una nueva arquitectura para admitir una especie de proceso aislado, de modo que pueda ejecutar Docker de forma nativa sin Hyper-V ni ninguna virtualizaci\u00f3n. A d\u00eda de hoy, Windows Server 2016 es el \u00fanico sistema de Windows que admite contenedores nativos, sin embargo, la imagen m\u00e1s b\u00e1sica es de 5 GB, lo que no es muy eficiente. El servidor de Windows ejecuta contenedores de Windows de forma nativa y usa Hyper-V para Linux. Adem\u00e1s, cuando ejecuta contenedores de Windows, no puede ejecutar los de Linux, por lo que debe elegir uno u otro. Dado que el 99% de las im\u00e1genes est\u00e1n basadas en Linux y .NET puede ejecutarse en Linux, los contenedores de Windows no son tan \u00fatiles. Sin embargo, actualmente Windows 10 Home es compatible con Docker. Utilizando WLS 2, que bajo el cap\u00f3 es una m\u00e1quina virtual, muy similar a Docker Toolbox pero mucho m\u00e1s eficiente. Nuevamente, para el desarrollo local deber\u00eda estar bien, pero Linux ser\u00e1 el sistema operativo que ejecutar\u00e1 el Docker de forma \u00f3ptima. En s\u00edntesis, muchos portales web sugieren la implementaci\u00f3n de dicha tecnolog\u00eda en un sistema operativo Linux. \u00bfQu\u00e9 ocurre con aquellas personas que no tienen sistema operativo Linux de forma nativa? Una soluci\u00f3n podr\u00eda ser recurrir a la virtualizaci\u00f3n mediante m\u00e1quinas virtuales de Virtual Box. \u00bfFunciona Docker en la implementaci\u00f3n de una virtualizaci\u00f3n? Si la m\u00e1quina virtual es Linux, puede hacer esto sin ning\u00fan problema; en Linux, el Docker es esencialmente un chroot bien trabajado. Por lo tanto, la ventana acoplable de Linux no es virtualizaci\u00f3n. En el caso de Windows, no es tan f\u00e1cil. El sistema operativo Windows utiliza Hyper-V internamente para emular los contenedores. Lo que significa que solo puede ejecutar, si puede utilizar la virtualizaci\u00f3n anidada. Lo que finalmente permite deducir que tampoco es posible implementar docker en un entorno virtualizado de Windows. En definitiva, la soluci\u00f3n para implementar esta tecnolog\u00eda pasa por instalar docker en un Linux nativo o virtualizado. Siempre y cuando la virtualizaci\u00f3n tenga todas las configuraciones \u00f3ptimas de virtualbox como plantea el tutorial presentado por Grzegorz Gajos en el portal de Medium. Conclusi\u00f3n , como ambos estudiantes poseen windows de forma nativa se recurrir\u00e1 a una virtualizaci\u00f3n de Ubuntu Bionic 18.04 sobre virtualbox para implementar Docker . Fuente de Informaci\u00f3n https://containerjournal.com/topics/container-ecosystems/the-differences-between-linux-and-windows-containers/ https://apiumhub.com/es/tech-blog-barcelona/usar-docker/ https://www.toolboxtve.com/es/por-que-usar-docker-cuando-la-infraestructura-se-vuelve-codigo/ https://medium.com/@javier.ramos1/docker-windows-vs-linux-1bb26d8090b3 https://stackoverrun.com/es/q/10941362 https://medium.com/faun/hey-docker-why-you-hate-windows-so-much-de7a7aa4dd7","title":"Home"},{"location":"#documentacion-trabajo-final-de-trafico","text":"La siguiente documentaci\u00f3n tiene como prop\u00f3sito exponer los conceptos que dan origen y sustento al trabajo final de Ger\u00f3nimo Passini y Lucas Gorordo para la asignatura \"Tr\u00e1fico\" de la carrera ingenier\u00eda de Telecomunicaciones.","title":"Documentaci\u00f3n Trabajo Final de Tr\u00e1fico"},{"location":"#en-que-se-basa-el-proyecto","text":"Antes de comenzar a dar detalles del proyecto, es importante tener en cuenta el concepto de Internet de las Cosas o tambi\u00e9n conocido como IoT, este se refiere a un gran n\u00famero de \u201ccosas\u201d u objetos que se conectan a Internet para que puedan compartir datos con otras cosas \u2013 aplicaciones para IoT, dispositivos conectados, m\u00e1quinas industriales y m\u00e1s. Los dispositivos conectados a Internet utilizan sensores integrados para reunir datos y, en algunos casos, realizar acciones con ellos. Los dispositivos y m\u00e1quinas conectados a Internet pueden mejorar nuestra forma de trabajar y de vivir. Algunos ejemplos reales de IoT van desde un hogar inteligente que ajusta autom\u00e1ticamente la calefacci\u00f3n y las luces hasta una f\u00e1brica inteligente que monitorea m\u00e1quinas industriales para buscar problemas y luego hace ajustes autom\u00e1ticos para evitar fallos. Los sistemas embebidos en este contexto son muy importantes, siempre y cuando est\u00e9n muy bien acompa\u00f1ados con una infraestructura de red que permita dar soporte a cientos de sensores y construir una aplicaci\u00f3n destinada al usuario final. En este sentido, es muy importante analizar el comportamiento de redes de sensores para una aplicaci\u00f3n en particular, en la que la cantidad de dispositivos inteligentes y su comportamiento juegan un rol fundamental. El presente trabajo tiene como finalidad poder crear un entorno de simulaci\u00f3n orientado a esquematizar una implementaci\u00f3n t\u00edpica, como suele suceder en el \u00e1rea de los sistemas embebidos, en b\u00fasqueda de poder realizar an\u00e1lisis de tr\u00e1fico en la etapa posterior a que ya se encuentre estable la etapa de adquisici\u00f3n de datos por los diversos sensores o perif\u00e9ricos que componen al proyecto.","title":"\u00bfEn qu\u00e9 se basa el proyecto?"},{"location":"#estructura-del-proyecto","text":"Todo el material expuesto en esta instancia, ronda a partir de la siguiente estructura: Servicio a implementar Generador de trafico Adquisici\u00f3n de m\u00e9tricas Visualizaci\u00f3n de m\u00e9tricas La misma pretende ser implementada en Docker para crear un esquema de trabajo portable sobre el cual realizar pruebas de performance .","title":"Estructura del proyecto"},{"location":"#docker-como-estructura-de-trabajo","text":"Dada la estructura del trabajo a realizar, la tecnolog\u00eda que mejor se adapta a la modalidad de desarrollo es Docker \u00bfPor qu\u00e9? porque permite tener control sobre cada una de las fases de vida de un producto. Una aplicaci\u00f3n incluye no solo la aplicaci\u00f3n como tal, sino que tenemos un motor, un conjunto de librer\u00edas y el kernel o software. Docker permite agrupar todo esto en un contenedor y almacenarlo en nuestro disco duro. De forma que copia todo lo que pertenece a un mismo sistema operativo y lo almacena en una zona de nuestro disco duro para luego ejecutarla independientemente del sistema operativo. Esto permite que se pueda transportar la aplicaci\u00f3n y ejecutarla donde se desee, sin preocuparse por el software o si tienes todos los componentes de la aplicaci\u00f3n para iniciarla. La portabilidad es la gran caracter\u00edstica que permite una evoluci\u00f3n continua y r\u00e1pida en el desarrollo de un programa y es precisamente lo que se necesita en este momento para la realizaci\u00f3n de trabajos grupales de manera remota. A nivel general, \u00bfQu\u00e9 ventajas adicionales aporta esta tecnolog\u00eda al desarrollo de software? \u2192 Facilita el testing, facilita la tarea, puesto que si tenemos instalado Docker en nuestro ordenador y nos pasan un contenedor con una App a testear. Da igual cual sea el software que tengamos, docker nos permitir\u00e1 abrir la app y poder probarla. \u2192 Ahorra tiempo, al no obligarnos a instalar diferentes softwares para poder ejecutar una App. \u2192 Es muy sencillo crear y eliminar contenedores. \u2192 Son muy ligeros, lo que nos permite manejar diferentes contenedores dentro de una misma m\u00e1quina. \u2192 Es open source. \u2192 Nos proporcionan autonom\u00eda, a partir de que en cada contenedor tenemos todo lo necesario para ejecutar una aplicaci\u00f3n. \u2192 Portabilidad: Al almacenar los contenedores en discos duros, estos se pueden transportar de un lugar a otro sin problemas. \u2192 Im\u00e1genes Docker: Podr\u00edamos definir estas im\u00e1genes como sistemas operativos con aplicaciones instaladas. En este SO, podremos incluir nuestras im\u00e1genes para su posterior visualizaci\u00f3n en un equipo. \u2192 Repositorios Docker: \u201cBanco de im\u00e1genes docker\u201d creadas por usuarios a las cuales podemos tener acceso. \u2192 Con Docker, tenemos capacidad de ejecutar pr\u00e1cticamente todas las aplicaciones facilitando el compartir las aplicaciones a trav\u00e9s de los contenedores. \u2192 Se acelera el proceso de mantenimiento y desarrollo gracias a las facilidades para generar copias. \u2192 Las aplicaciones se ejecutan sin variaciones. Sin importar el equipo ni el ambiente. \u2192 Es un entorno seguro y no ofrece variaciones.","title":"Docker como estructura de trabajo"},{"location":"#que-sistemas-operativos-admiten-docker","text":"Docker puede instalarse tanto en Linux como en Windows, pero es necesario agregar algunas particularidades al an\u00e1lisis. Con respecto a el mundo de Linux, Docker es una plataforma de c\u00f3digo abierto (en su mayor\u00eda) que funciona con cualquier distribuci\u00f3n de Linux de cualquier proveedor. En sus inicios, Docker no trabaj\u00f3 en estrecha colaboraci\u00f3n con ninguna empresa en particular en el espacio de Linux para desarrollar contenedores o hacer que funcionen con Linux. Pero no ocurre lo mismo con Windows, para este caso, Docker y Microsoft trabajaron en estrecha colaboraci\u00f3n para llevar contenedores a Windows. Esta diferencia puede ser importante para el usuario si se piensa en la longevidad o flexibilidad de los contenedores en Windows. Ya que, si Microsoft decidiera en el futuro dejar de admitir contenedores, probablemente ser\u00e1 el final de los contenedores en Windows. En Linux, estos riesgos no existen. Incluso si Docker decidiera detener el desarrollo, el ecosistema de contenedores ahora es tan din\u00e1mico y grande que otros proyectos de c\u00f3digo abierto probablemente tomar\u00edan el relevo y garantizar\u00edan que los contenedores de Linux sigan siendo viables. Para decirlo de otra manera: Se podr\u00e1 utilizar contenedores en Windows dentro de 10 a\u00f1os depende en gran medida de lo que Microsoft decida hacer. En Linux, es una apuesta mucho m\u00e1s segura que los contenedores seguir\u00e1n funcionando en una d\u00e9cada, independientemente de las elecciones que tome un proveedor en particular. Pese a esta independencia entre Linux y Docker, hay que destacar que la arquitectura de Docker es muy eficiente dentro de un sistema operativo Linux. \u00bfPero qu\u00e9 ocurre con Windows? El primer enfoque para admitir Docker en Windows fue Docker Toolbox, que es b\u00e1sicamente una m\u00e1quina virtual que utiliza Virtual Box con una imagen de Linux. Entonces, como sugiere el nombre, es solo una herramienta para aprender Docker, pero no es muy \u00fatil ya que es una VM normal. Con Windows 10 Pro, Microsoft present\u00f3 Hyper-V, que es una herramienta de virtualizaci\u00f3n s\u00faper r\u00e1pida, Docker para Windows se lanz\u00f3 para Windows 10 Pro, para ejecutar contenedores mucho m\u00e1s r\u00e1pido y m\u00e1s f\u00e1cil, pero en un principio se necesitaba Windows 10 \u201cPro\u201d, por lo que en \u201cHome\u201d no funcionaba. Cuando se lanz\u00f3 Windows Server 2016, fue una nueva arquitectura para admitir una especie de proceso aislado, de modo que pueda ejecutar Docker de forma nativa sin Hyper-V ni ninguna virtualizaci\u00f3n. A d\u00eda de hoy, Windows Server 2016 es el \u00fanico sistema de Windows que admite contenedores nativos, sin embargo, la imagen m\u00e1s b\u00e1sica es de 5 GB, lo que no es muy eficiente. El servidor de Windows ejecuta contenedores de Windows de forma nativa y usa Hyper-V para Linux. Adem\u00e1s, cuando ejecuta contenedores de Windows, no puede ejecutar los de Linux, por lo que debe elegir uno u otro. Dado que el 99% de las im\u00e1genes est\u00e1n basadas en Linux y .NET puede ejecutarse en Linux, los contenedores de Windows no son tan \u00fatiles. Sin embargo, actualmente Windows 10 Home es compatible con Docker. Utilizando WLS 2, que bajo el cap\u00f3 es una m\u00e1quina virtual, muy similar a Docker Toolbox pero mucho m\u00e1s eficiente. Nuevamente, para el desarrollo local deber\u00eda estar bien, pero Linux ser\u00e1 el sistema operativo que ejecutar\u00e1 el Docker de forma \u00f3ptima. En s\u00edntesis, muchos portales web sugieren la implementaci\u00f3n de dicha tecnolog\u00eda en un sistema operativo Linux. \u00bfQu\u00e9 ocurre con aquellas personas que no tienen sistema operativo Linux de forma nativa? Una soluci\u00f3n podr\u00eda ser recurrir a la virtualizaci\u00f3n mediante m\u00e1quinas virtuales de Virtual Box. \u00bfFunciona Docker en la implementaci\u00f3n de una virtualizaci\u00f3n? Si la m\u00e1quina virtual es Linux, puede hacer esto sin ning\u00fan problema; en Linux, el Docker es esencialmente un chroot bien trabajado. Por lo tanto, la ventana acoplable de Linux no es virtualizaci\u00f3n. En el caso de Windows, no es tan f\u00e1cil. El sistema operativo Windows utiliza Hyper-V internamente para emular los contenedores. Lo que significa que solo puede ejecutar, si puede utilizar la virtualizaci\u00f3n anidada. Lo que finalmente permite deducir que tampoco es posible implementar docker en un entorno virtualizado de Windows. En definitiva, la soluci\u00f3n para implementar esta tecnolog\u00eda pasa por instalar docker en un Linux nativo o virtualizado. Siempre y cuando la virtualizaci\u00f3n tenga todas las configuraciones \u00f3ptimas de virtualbox como plantea el tutorial presentado por Grzegorz Gajos en el portal de Medium. Conclusi\u00f3n , como ambos estudiantes poseen windows de forma nativa se recurrir\u00e1 a una virtualizaci\u00f3n de Ubuntu Bionic 18.04 sobre virtualbox para implementar Docker .","title":"\u00bfQu\u00e9 sistemas operativos admiten docker?"},{"location":"#fuente-de-informacion","text":"https://containerjournal.com/topics/container-ecosystems/the-differences-between-linux-and-windows-containers/ https://apiumhub.com/es/tech-blog-barcelona/usar-docker/ https://www.toolboxtve.com/es/por-que-usar-docker-cuando-la-infraestructura-se-vuelve-codigo/ https://medium.com/@javier.ramos1/docker-windows-vs-linux-1bb26d8090b3 https://stackoverrun.com/es/q/10941362 https://medium.com/faun/hey-docker-why-you-hate-windows-so-much-de7a7aa4dd7","title":"Fuente de Informaci\u00f3n"},{"location":"PruebasPerformance/","text":"Pruebas de Performance \u00bfQue es una prueba de performance? Un performance test o prueba de rendimiento apunta a indagar sobre el comportamiento de una aplicaci\u00f3n cuando se genera una alta demanda de uso. Es una situaci\u00f3n muy com\u00fan en aplicaciones corporativas, en soluciones de e-commerce, servicios en l\u00ednea para la oferta de productos en fechas especiales, asi como tambien en arquitecturas de redes correspondientes a sistemas IoT. En definitiva, el performance test consiste en someter una aplicaci\u00f3n a distintas pruebas para determinar su comportamiento en circunstancias de carga extrema de trabajo. El objetivo principal es determinar si la aplicaci\u00f3n se comporta como se espera, principalmente cuando el volumen de trabajo es grande. No opera sobre posibles errores en la aplicaci\u00f3n espec\u00edficamente. Lo que busca es determinar el desempe\u00f1o general del sistema y detectar cuellos de botella que puedan desestabilizar la aplicaci\u00f3n y afectar la buena experiencia del usuario. Durante el performance test se toman en cuenta diferentes indicadores como: nivel de respuesta, velocidad, escalabilidad y estabilidad, recursos consumidos, entre otros. Para llevar a cabo un test de esta naturaleza, se simula de la manera m\u00e1s realista posible la aplicaci\u00f3n, y se ejecuta de distintas maneras y en diferentes situaciones de uso. Por ejemplo, es ideal para determinar el comportamiento de una aplicaci\u00f3n cuando ingresan en forma simult\u00e1nea varios, cientos, miles de usuarios. Permite medir su rendimiento cuando se ejecutan algunas operaciones. Al finalizar las pruebas, se analizan todos los datos generados evaluando el desempe\u00f1o general de la aplicaci\u00f3n. En caso de encontrar anomal\u00edas comienza un profundo trabajo de investigaci\u00f3n para detectar los problemas del sistema. Puede tratarse de aspectos referidos a la aplicaci\u00f3n misma, el software de soporte como Bases de Datos, el sistema operativo, fallas en el hardware, como el servidor, servidores redundantes o la infraestructura de la red. Distintos tipos de performance test Un performance test implica realizar varios tipos de pruebas espec\u00edficas para conocer el comportamiento en distintas situaciones. Alguna de estas pruebas se describe a continuaci\u00f3n. Test de carga , en ese caso la carga de la aplicaci\u00f3n se va incrementando progresivamente hasta cierto punto. Por ejemplo, se van incrementando la cantidad de usuarios que utilizan la aplicaci\u00f3n o la cantidad de transacciones que se realizan simult\u00e1neamente. Test de Stress , se prueba la estabilidad del sistema cuando los recursos de hardware son insuficientes como la CPU, memoria o el espacio en disco duro. Test de volumen , en este caso se somete a la aplicaci\u00f3n a grandes vol\u00famenes de datos a procesar para validar la eficiencia y probar as\u00ed el desempe\u00f1o de la Base de Datos. Pruebas de performance de nuestro Proyecto La finalidad de toda la arquitectura de red detallada en este trabajo, consiste en servir como banco de prueba para realizar test de performance sobre diferentes aplicaciones web. En esta instancia toco django, pero podria desplegarse cualquier otra tecnologia de servicios web para realizar pruebas. Como en este caso se plantea una aplicacion para IoT, las pruebas de performance estaran destinadas a: Determinar la cantidad maxima de usuarios simultaneos soportados por el sistema. Determinar la cantidad maxima de usuarios por segundo Iniciales que soporta el sistema. Determinar el consumo de recursos (CPU y Memoria RAM) para diferentes modelos de trafico. Determinar si el sistema es estable o permanecera estable para cada uno de los escenarios. Gestionar diferentes pruebas para diferentes hardware (PC Escritorio y Notebook) y comparar resultados. Determinar la importancia de los parametros del sistema en el rendimiento de las diferentes pruebas Determinar las diferencias que existen entre diferentes bases de datos (SQLite3 y PostgreSQL) en cuestiones de rendimiento. Para ello, se realizaron tres modelos de trafico que ejecutaran diferentes pruebas, considerando que el recurso destinado a RAM ira desde 4GB a 11GB y la cantidad de CPU desde 2 CPU a 4 CPU. Cada modelo de trafico esta rotulado como : Trafico Pesado , Trafico Intermedio y Trafico Liviano dependiendo de las caracteristicas de los sensores. El trafico denominado como pesado tiene las siguientes caracteristicas: Tiempo entre tareas asociadas a un mismo sensor : 15 min Tiempo entre tareas asociadas a un usuario: 2 a 6 min El trafico intermedio se caracteriza por los siguientes parametros: Tiempo entre tareas asociadas a un mismo sensor: 30 min Tiempo entre tareas asociadas a un usuario: 4 a 12 min En ultima instancia, el trafico liviano se caracteriza por los siguientes parametros: Tiempo entre tareas asociadas a un mismo sensor: 60 min Tiempo entre tareas asociadas a un usuario: 10 a 15 min Todas los modelos comparten ciertas caracteristicas en comun: Probabilidad de Ocurrencia de un sensor 1/3 Probabilidad de Ocurrencia de un consumidor 2/3 Cada modelo sera puesto a prueba con una cantidad de usuarios de 300-600-900 La combinacion entre modelo y cantidad de usuarios, permite generar un set de lambda (Cantidad de usuarios por segundo que se hacen presentes en el sitio web de forma simultanea) donde el valor minimo en todos los casos sera 1 y el valor maximo 25% de la cantidad maxima de usuarios. Estas combinaciones (Modelo-Cantidad de usuarios - Lambda) se encuadran dentro de las diferentes categorias de acuerdo a la cantidad de recursos con los que cuenta el servidor. Se crearon 3 categorias: 2 CPU - 4 GB RAM (recursos bajos) , 2 CPU - 6 GB RAM (recursos intermedios) , 4 CPU - 11 GB RAM (recursos altos) De esta forma, es posible generar un total de 27 pruebas de performance por cada combinacion de recurso que sea asignado al servidor. Como se realizaran 3 combinaciones diferentes, habria en total una cantidad de 81 pruebas diferentes. A continuacion, se muestra una imagen que resume los puntos tratados anteriormente: Resultados Antes de presentar los resultados es necesario mencionar que todo el set de pruebas fue elaborado entre dos maquinas Host diferentes. Cada una de ellas, efectuo aquellas pruebas de performance que fueran adecuadas respecto a sus recursos, ya que no tienen la misma cantidad de memoria RAM, ni los mismos procesadores y por sobre todas las cosas, difieren en tama\u00f1o, ya que estamos frente a una maquina de escritorio y una notebook, por lo que es un detalle a no perder de vista. Las caracteristicas tecnicas de la PC de escritorio son: Procesador: AMD FX(tm)-4300 Quad Core Processor 3,80 Ghz Memoria RAM: 8 GB Las caracteristicas tecnicas de la Notebook son: Procesador: Intel Core i7 \u2013 7700HQ CPU a 2.8Ghz Memoria RAM: 16 GB Los resultados dejan en evidencia r\u00e1pidamente que independientemente del modelo de tr\u00e1fico aplicado, el funcionamiento del sitio web es \u00f3ptimo para 300 usuarios. Esto qued\u00f3 totalmente demostrado al realizar y superar las pruebas de performance m\u00e1s cr\u00edticas dentro de todo el set. Lo que significa que se utiliz\u00f3 la menor cantidad de CPU, la menor cantidad de memoria RAM y el modelado m\u00e1s exigente (tr\u00e1fico pesado) y aun as\u00ed el servidor fue capaz de responder a cada consulta en tiempo y forma y optimizar el uso de recursos. \u00bfQu\u00e9 significa responder en tiempo y forma? Que el servidor logr\u00f3 dos cuestiones fundamentales en cuanto a la carga de datos y consulta de los mismos: Las respuestas a las diferentes cargas iniciales tardaron menos de 15 min. por lo tanto los sensores pudieron generar su flujo de informaci\u00f3n peri\u00f3dica sin ning\u00fan compromiso. El sistema soporto el pico de tr\u00e1fico inicial y supo responder frente a ello. Las consultas para observar datos a pesar de generarse cada 2 a 4 min. no superaron el periodo de 15 min en cuanto al tiempo de respuesta, lo que significa que quien realizaba las consultas pudo observar correctamente los datos en su momento y actualizados. Es notable la dificultad que presenta el sistema frente a las escrituras sobre la base de datos, ya que cuando existen cargas de sensores los tiempos de respuesta se disparan y generan picos, lo que significa que todo el sistema se vuelve m\u00e1s lento. Adem\u00e1s, depende del gestor de base de datos utilizado para la aplicaci\u00f3n. En el caso de SQLite3 existen grandes problemas de concurrencia, que pueden observarse en las pruebas de performance con 38 usuarios/seg y 75 usuarios/seg, lo que genera una gran cantidad de bloqueos (errores 500 server) y demoras para resolver las diferentes solicitudes de escritura sobre la base de datos. Distinto de lo que ocurre al aplicar PostgreSQL. Con este \u00faltimo, las conexiones activas aumentan pero sobreviven al bloqueo, lo que da mayor probabilidad de \u00e9xito a una consulta aunque los tiempos de respuesta aumentan. Es necesario mencionar que es posible configurar la cantidad m\u00e1xima de conexiones simult\u00e1neas, lo que significa un cambio importante y fundamental entre SQLite3 y postgreSQL. Sin embargo, si se decide mantener un n\u00famero peque\u00f1o de conexiones activas simult\u00e1neas, el sistema funciona de forma eficiente de todos modos, ya que cuando la base de datos est\u00e1 colapsada de solicitudes, rechaza r\u00e1pidamente las nuevas solicitudes entrantes y no pierde tiempo tratando de resolverlas a diferencia de SQLite3 que si espera y da oportunidades a todas las solicitudes. Las lecturas sobre la base de datos parecen ser m\u00e1s sencillas de resolver para el sistema, ya que a pesar de ser la mayor masa de tr\u00e1fico, pueden observarse tiempos de respuesta muy buenos una vez superada la carga inicial. \u00bfQu\u00e9 ocurre con el consumo de recursos? Respecto al consumo de CPU parecer\u00eda ser un enigma, ya que se esperar\u00eda que mientras mayor es el nivel de concurrencia, mayor trabajo por parte del hardware y niveles m\u00e1ximos de CPU cada vez m\u00e1s grandes. Pero esto no es necesariamente as\u00ed, ya que simulaci\u00f3n a simulaci\u00f3n los comportamientos tienden a ser variables y no siempre muestran una clara tendencia. Respecto al consumo de RAM puede verse una clara diferencia entre simulaciones con y sin concurrencia. Para aquellas pruebas donde la concurrencia es alta, si el sistema soporta la carga de tr\u00e1fico, presenta una curva de consumo de RAM muy particular. Primero crece r\u00e1pidamente hasta alcanzar un m\u00e1ximo y luego decrece r\u00e1pidamente para establecerse en un valor constante. Si el sistema presenta poca concurrencia, la curva de consumo de ram parece escalonada en muchos casos o una exponencial positiva de crecimiento lento tendiendo a un valor m\u00e1ximo fijo. En aquellos casos donde el sistema no soporta la carga de tr\u00e1fico, consume toda la RAM y genera microcortes muy marcados o cortes totales en el funcionamiento hasta dejar al servidor fuera de servicio. Estas son algunas de las caracter\u00edsticas de las simulaciones de tr\u00e1fico pesado con 300 usuarios. Respecto a las simulaciones de 600 usuarios, los resultados mostraron un claro comportamiento. En el caso de tr\u00e1fico pesado, el sistema no funciona para ning\u00fan caso diferente al de 1 usuario/seg (sin concurrencia) de los planteados. Lo que genera una gran sospecha, ya que cuando se observan los tiempos de respuesta y comportamientos para la prueba que si funciona, el sistema es muy estable. El agotamiento de RAM lleva a que el servidor sea cada vez m\u00e1s lento o directamente se paralice, lo que genera que el tr\u00e1fico pendiente se le acumule cada vez m\u00e1s y los tiempos de respuesta se disparen. Esta situaci\u00f3n no tendr\u00eda soluci\u00f3n alguna, ya que si el servidor no es capaz de responder m\u00e1s r\u00e1pido, la situaci\u00f3n de colapso por RAM no es posible de evitar. Si se sigue aumentando la cantidad de usuarios en este modelo de tr\u00e1fico, los resultados son desalentadores. El sistema no soporta ninguna de las pruebas. En poco tiempo iniciada la simulaci\u00f3n se agota la memoria RAM por lo que el servidor colapsa. Al migrar el modelo de tr\u00e1fico a una carga intermedia, el \u00fanico logro fue incorporar como pruebas exitosas a las de 900 usuarios con una concurrencia de 1 usuario /seg. Sin embargo, el resto de pruebas que fallaron en el modelo de tr\u00e1fico pesado, fallaron nuevamente en este modelo. Finalmente, al incorporar al an\u00e1lisis el modelo de tr\u00e1fico liviano, puede observarse la notable mejora en las pruebas de rendimiento para 600 usuarios con concurrencias desde 75 usuarios/seg a 150 usuarios/seg a partir de un nivel m\u00ednimo de recursos (2 CPU y 6 GB RAM), dando la pauta que cuando el modelo de tr\u00e1fico es m\u00e1s relajado, la cantidad de usuarios simult\u00e1nea y la concurrencia pueden ser mucho m\u00e1s elevadas. Sin embargo, en este modelo las pruebas de 900 usuarios con concurrencia fallaron nuevamente, lo que nos dice que bajo cualquier modelo, las pruebas de 900 usuarios representa un l\u00edmite superior muy marcado para las prestaciones y servicios/contenedores implementados. A pesar de esto, los 600 usuarios simult\u00e1neos es un factor posible de alcanzar dependiendo el nivel de tr\u00e1fico y los 300 usuarios representa el uso real que puede soportar este esquema. En caso de querer observar particularidades de las diversas pruebas, se puede acceder a los siguientes documentos: Pruebas Livianas Pruebas Intermedias Pruebas Pesadas","title":"Pruebas de Performance"},{"location":"PruebasPerformance/#pruebas-de-performance","text":"","title":"Pruebas de Performance"},{"location":"PruebasPerformance/#que-es-una-prueba-de-performance","text":"Un performance test o prueba de rendimiento apunta a indagar sobre el comportamiento de una aplicaci\u00f3n cuando se genera una alta demanda de uso. Es una situaci\u00f3n muy com\u00fan en aplicaciones corporativas, en soluciones de e-commerce, servicios en l\u00ednea para la oferta de productos en fechas especiales, asi como tambien en arquitecturas de redes correspondientes a sistemas IoT. En definitiva, el performance test consiste en someter una aplicaci\u00f3n a distintas pruebas para determinar su comportamiento en circunstancias de carga extrema de trabajo. El objetivo principal es determinar si la aplicaci\u00f3n se comporta como se espera, principalmente cuando el volumen de trabajo es grande. No opera sobre posibles errores en la aplicaci\u00f3n espec\u00edficamente. Lo que busca es determinar el desempe\u00f1o general del sistema y detectar cuellos de botella que puedan desestabilizar la aplicaci\u00f3n y afectar la buena experiencia del usuario. Durante el performance test se toman en cuenta diferentes indicadores como: nivel de respuesta, velocidad, escalabilidad y estabilidad, recursos consumidos, entre otros. Para llevar a cabo un test de esta naturaleza, se simula de la manera m\u00e1s realista posible la aplicaci\u00f3n, y se ejecuta de distintas maneras y en diferentes situaciones de uso. Por ejemplo, es ideal para determinar el comportamiento de una aplicaci\u00f3n cuando ingresan en forma simult\u00e1nea varios, cientos, miles de usuarios. Permite medir su rendimiento cuando se ejecutan algunas operaciones. Al finalizar las pruebas, se analizan todos los datos generados evaluando el desempe\u00f1o general de la aplicaci\u00f3n. En caso de encontrar anomal\u00edas comienza un profundo trabajo de investigaci\u00f3n para detectar los problemas del sistema. Puede tratarse de aspectos referidos a la aplicaci\u00f3n misma, el software de soporte como Bases de Datos, el sistema operativo, fallas en el hardware, como el servidor, servidores redundantes o la infraestructura de la red.","title":"\u00bfQue es una prueba de performance?"},{"location":"PruebasPerformance/#distintos-tipos-de-performance-test","text":"Un performance test implica realizar varios tipos de pruebas espec\u00edficas para conocer el comportamiento en distintas situaciones. Alguna de estas pruebas se describe a continuaci\u00f3n. Test de carga , en ese caso la carga de la aplicaci\u00f3n se va incrementando progresivamente hasta cierto punto. Por ejemplo, se van incrementando la cantidad de usuarios que utilizan la aplicaci\u00f3n o la cantidad de transacciones que se realizan simult\u00e1neamente. Test de Stress , se prueba la estabilidad del sistema cuando los recursos de hardware son insuficientes como la CPU, memoria o el espacio en disco duro. Test de volumen , en este caso se somete a la aplicaci\u00f3n a grandes vol\u00famenes de datos a procesar para validar la eficiencia y probar as\u00ed el desempe\u00f1o de la Base de Datos.","title":"Distintos tipos de performance test"},{"location":"PruebasPerformance/#pruebas-de-performance-de-nuestro-proyecto","text":"La finalidad de toda la arquitectura de red detallada en este trabajo, consiste en servir como banco de prueba para realizar test de performance sobre diferentes aplicaciones web. En esta instancia toco django, pero podria desplegarse cualquier otra tecnologia de servicios web para realizar pruebas. Como en este caso se plantea una aplicacion para IoT, las pruebas de performance estaran destinadas a: Determinar la cantidad maxima de usuarios simultaneos soportados por el sistema. Determinar la cantidad maxima de usuarios por segundo Iniciales que soporta el sistema. Determinar el consumo de recursos (CPU y Memoria RAM) para diferentes modelos de trafico. Determinar si el sistema es estable o permanecera estable para cada uno de los escenarios. Gestionar diferentes pruebas para diferentes hardware (PC Escritorio y Notebook) y comparar resultados. Determinar la importancia de los parametros del sistema en el rendimiento de las diferentes pruebas Determinar las diferencias que existen entre diferentes bases de datos (SQLite3 y PostgreSQL) en cuestiones de rendimiento. Para ello, se realizaron tres modelos de trafico que ejecutaran diferentes pruebas, considerando que el recurso destinado a RAM ira desde 4GB a 11GB y la cantidad de CPU desde 2 CPU a 4 CPU. Cada modelo de trafico esta rotulado como : Trafico Pesado , Trafico Intermedio y Trafico Liviano dependiendo de las caracteristicas de los sensores. El trafico denominado como pesado tiene las siguientes caracteristicas: Tiempo entre tareas asociadas a un mismo sensor : 15 min Tiempo entre tareas asociadas a un usuario: 2 a 6 min El trafico intermedio se caracteriza por los siguientes parametros: Tiempo entre tareas asociadas a un mismo sensor: 30 min Tiempo entre tareas asociadas a un usuario: 4 a 12 min En ultima instancia, el trafico liviano se caracteriza por los siguientes parametros: Tiempo entre tareas asociadas a un mismo sensor: 60 min Tiempo entre tareas asociadas a un usuario: 10 a 15 min Todas los modelos comparten ciertas caracteristicas en comun: Probabilidad de Ocurrencia de un sensor 1/3 Probabilidad de Ocurrencia de un consumidor 2/3 Cada modelo sera puesto a prueba con una cantidad de usuarios de 300-600-900 La combinacion entre modelo y cantidad de usuarios, permite generar un set de lambda (Cantidad de usuarios por segundo que se hacen presentes en el sitio web de forma simultanea) donde el valor minimo en todos los casos sera 1 y el valor maximo 25% de la cantidad maxima de usuarios. Estas combinaciones (Modelo-Cantidad de usuarios - Lambda) se encuadran dentro de las diferentes categorias de acuerdo a la cantidad de recursos con los que cuenta el servidor. Se crearon 3 categorias: 2 CPU - 4 GB RAM (recursos bajos) , 2 CPU - 6 GB RAM (recursos intermedios) , 4 CPU - 11 GB RAM (recursos altos) De esta forma, es posible generar un total de 27 pruebas de performance por cada combinacion de recurso que sea asignado al servidor. Como se realizaran 3 combinaciones diferentes, habria en total una cantidad de 81 pruebas diferentes. A continuacion, se muestra una imagen que resume los puntos tratados anteriormente:","title":"Pruebas de performance de nuestro Proyecto"},{"location":"PruebasPerformance/#resultados","text":"Antes de presentar los resultados es necesario mencionar que todo el set de pruebas fue elaborado entre dos maquinas Host diferentes. Cada una de ellas, efectuo aquellas pruebas de performance que fueran adecuadas respecto a sus recursos, ya que no tienen la misma cantidad de memoria RAM, ni los mismos procesadores y por sobre todas las cosas, difieren en tama\u00f1o, ya que estamos frente a una maquina de escritorio y una notebook, por lo que es un detalle a no perder de vista. Las caracteristicas tecnicas de la PC de escritorio son: Procesador: AMD FX(tm)-4300 Quad Core Processor 3,80 Ghz Memoria RAM: 8 GB Las caracteristicas tecnicas de la Notebook son: Procesador: Intel Core i7 \u2013 7700HQ CPU a 2.8Ghz Memoria RAM: 16 GB Los resultados dejan en evidencia r\u00e1pidamente que independientemente del modelo de tr\u00e1fico aplicado, el funcionamiento del sitio web es \u00f3ptimo para 300 usuarios. Esto qued\u00f3 totalmente demostrado al realizar y superar las pruebas de performance m\u00e1s cr\u00edticas dentro de todo el set. Lo que significa que se utiliz\u00f3 la menor cantidad de CPU, la menor cantidad de memoria RAM y el modelado m\u00e1s exigente (tr\u00e1fico pesado) y aun as\u00ed el servidor fue capaz de responder a cada consulta en tiempo y forma y optimizar el uso de recursos. \u00bfQu\u00e9 significa responder en tiempo y forma? Que el servidor logr\u00f3 dos cuestiones fundamentales en cuanto a la carga de datos y consulta de los mismos: Las respuestas a las diferentes cargas iniciales tardaron menos de 15 min. por lo tanto los sensores pudieron generar su flujo de informaci\u00f3n peri\u00f3dica sin ning\u00fan compromiso. El sistema soporto el pico de tr\u00e1fico inicial y supo responder frente a ello. Las consultas para observar datos a pesar de generarse cada 2 a 4 min. no superaron el periodo de 15 min en cuanto al tiempo de respuesta, lo que significa que quien realizaba las consultas pudo observar correctamente los datos en su momento y actualizados. Es notable la dificultad que presenta el sistema frente a las escrituras sobre la base de datos, ya que cuando existen cargas de sensores los tiempos de respuesta se disparan y generan picos, lo que significa que todo el sistema se vuelve m\u00e1s lento. Adem\u00e1s, depende del gestor de base de datos utilizado para la aplicaci\u00f3n. En el caso de SQLite3 existen grandes problemas de concurrencia, que pueden observarse en las pruebas de performance con 38 usuarios/seg y 75 usuarios/seg, lo que genera una gran cantidad de bloqueos (errores 500 server) y demoras para resolver las diferentes solicitudes de escritura sobre la base de datos. Distinto de lo que ocurre al aplicar PostgreSQL. Con este \u00faltimo, las conexiones activas aumentan pero sobreviven al bloqueo, lo que da mayor probabilidad de \u00e9xito a una consulta aunque los tiempos de respuesta aumentan. Es necesario mencionar que es posible configurar la cantidad m\u00e1xima de conexiones simult\u00e1neas, lo que significa un cambio importante y fundamental entre SQLite3 y postgreSQL. Sin embargo, si se decide mantener un n\u00famero peque\u00f1o de conexiones activas simult\u00e1neas, el sistema funciona de forma eficiente de todos modos, ya que cuando la base de datos est\u00e1 colapsada de solicitudes, rechaza r\u00e1pidamente las nuevas solicitudes entrantes y no pierde tiempo tratando de resolverlas a diferencia de SQLite3 que si espera y da oportunidades a todas las solicitudes. Las lecturas sobre la base de datos parecen ser m\u00e1s sencillas de resolver para el sistema, ya que a pesar de ser la mayor masa de tr\u00e1fico, pueden observarse tiempos de respuesta muy buenos una vez superada la carga inicial. \u00bfQu\u00e9 ocurre con el consumo de recursos? Respecto al consumo de CPU parecer\u00eda ser un enigma, ya que se esperar\u00eda que mientras mayor es el nivel de concurrencia, mayor trabajo por parte del hardware y niveles m\u00e1ximos de CPU cada vez m\u00e1s grandes. Pero esto no es necesariamente as\u00ed, ya que simulaci\u00f3n a simulaci\u00f3n los comportamientos tienden a ser variables y no siempre muestran una clara tendencia. Respecto al consumo de RAM puede verse una clara diferencia entre simulaciones con y sin concurrencia. Para aquellas pruebas donde la concurrencia es alta, si el sistema soporta la carga de tr\u00e1fico, presenta una curva de consumo de RAM muy particular. Primero crece r\u00e1pidamente hasta alcanzar un m\u00e1ximo y luego decrece r\u00e1pidamente para establecerse en un valor constante. Si el sistema presenta poca concurrencia, la curva de consumo de ram parece escalonada en muchos casos o una exponencial positiva de crecimiento lento tendiendo a un valor m\u00e1ximo fijo. En aquellos casos donde el sistema no soporta la carga de tr\u00e1fico, consume toda la RAM y genera microcortes muy marcados o cortes totales en el funcionamiento hasta dejar al servidor fuera de servicio. Estas son algunas de las caracter\u00edsticas de las simulaciones de tr\u00e1fico pesado con 300 usuarios. Respecto a las simulaciones de 600 usuarios, los resultados mostraron un claro comportamiento. En el caso de tr\u00e1fico pesado, el sistema no funciona para ning\u00fan caso diferente al de 1 usuario/seg (sin concurrencia) de los planteados. Lo que genera una gran sospecha, ya que cuando se observan los tiempos de respuesta y comportamientos para la prueba que si funciona, el sistema es muy estable. El agotamiento de RAM lleva a que el servidor sea cada vez m\u00e1s lento o directamente se paralice, lo que genera que el tr\u00e1fico pendiente se le acumule cada vez m\u00e1s y los tiempos de respuesta se disparen. Esta situaci\u00f3n no tendr\u00eda soluci\u00f3n alguna, ya que si el servidor no es capaz de responder m\u00e1s r\u00e1pido, la situaci\u00f3n de colapso por RAM no es posible de evitar. Si se sigue aumentando la cantidad de usuarios en este modelo de tr\u00e1fico, los resultados son desalentadores. El sistema no soporta ninguna de las pruebas. En poco tiempo iniciada la simulaci\u00f3n se agota la memoria RAM por lo que el servidor colapsa. Al migrar el modelo de tr\u00e1fico a una carga intermedia, el \u00fanico logro fue incorporar como pruebas exitosas a las de 900 usuarios con una concurrencia de 1 usuario /seg. Sin embargo, el resto de pruebas que fallaron en el modelo de tr\u00e1fico pesado, fallaron nuevamente en este modelo. Finalmente, al incorporar al an\u00e1lisis el modelo de tr\u00e1fico liviano, puede observarse la notable mejora en las pruebas de rendimiento para 600 usuarios con concurrencias desde 75 usuarios/seg a 150 usuarios/seg a partir de un nivel m\u00ednimo de recursos (2 CPU y 6 GB RAM), dando la pauta que cuando el modelo de tr\u00e1fico es m\u00e1s relajado, la cantidad de usuarios simult\u00e1nea y la concurrencia pueden ser mucho m\u00e1s elevadas. Sin embargo, en este modelo las pruebas de 900 usuarios con concurrencia fallaron nuevamente, lo que nos dice que bajo cualquier modelo, las pruebas de 900 usuarios representa un l\u00edmite superior muy marcado para las prestaciones y servicios/contenedores implementados. A pesar de esto, los 600 usuarios simult\u00e1neos es un factor posible de alcanzar dependiendo el nivel de tr\u00e1fico y los 300 usuarios representa el uso real que puede soportar este esquema. En caso de querer observar particularidades de las diversas pruebas, se puede acceder a los siguientes documentos: Pruebas Livianas Pruebas Intermedias Pruebas Pesadas","title":"Resultados"},{"location":"adquisicionDeMetricas/","text":"Adquisici\u00f3n de M\u00e9tricas \u00bfQue es CAdvisor? cAdvisor (abreviatura de c ontainer Advisor ) analiza y expone el uso de recursos y los datos de rendimiento de los contenedores en ejecuci\u00f3n. Dentro de sus principales caracter\u00edsticas podemos destacar: cAdvisor es un recopilador de uso de recursos de contenedores de c\u00f3digo abierto. Soporte nativo para contenedores Docker y solo admite otros tipos de contenedores. cAdvisor funciona por nodo. Detecta autom\u00e1ticamente todos los contenedores en el nodo dado y recopila estad\u00edsticas de uso de la CPU, la memoria, el sistema de archivos y la red. Soporte para ejecutar de forma independiente fuera de Docker o cualquier otro contenedor. Proporciona el uso general de la m\u00e1quina analizando el contenedor 'ra\u00edz' en la m\u00e1quina. Admite la exportaci\u00f3n de estad\u00edsticas a varios complementos de almacenamiento, por ejemplo, Elasticsearch, InfluxDB, etc. Las m\u00e9tricas se pueden ver en la interfaz de usuario web, /containers que exporta informaci\u00f3n en vivo sobre todos los contenedores en la m\u00e1quina. Expone estad\u00edsticas sin procesar y procesadas a trav\u00e9s de una API REST remota versionada. Limitaciones Recopila la utilizaci\u00f3n de recursos b\u00e1sicos, es decir, no podr\u00edamos obtener el rendimiento real de las aplicaciones de contenedor, por ejemplo, x% de utilizaci\u00f3n de CPU No ofrece capacidades de an\u00e1lisis, tendencias o almacenamiento a largo plazo. \u00bfComo se observa el panel de administracion para monitorear las pruebas de rendimiento? Una vez desplegado el contenedor, podemos acceder via web a traves de https://127.0.0.1:8080 y se abrir\u00e1 una interfaz bastante sencilla e intuitiva, la cual nos va a mostrar los recursos del sistema y el listado de contendores que tenemos desplegados. \u00bfQue es Django Debug? Django Debug como su nombre lo indica, es una herramienta que permite vigilar el rendimiento de una aplicacion desarrollada en Django.Nos proporciona entre otras cosas: informaci\u00f3n de consultas de base de datos, templates usadas y tiempos de carga. \u00bfQue preguntas nos ayuda a responder? \u00bfCu\u00e1ntas consultas SQL se ejecutaron? \u00bfCu\u00e1l fue el tiempo acumulado en la base de datos? \u00bfQu\u00e9 consultas individuales se ejecutaron y cu\u00e1nto tiempo tom\u00f3 cada una? \u00bfQu\u00e9 c\u00f3digo genera cada consulta? \u00bfQu\u00e9 plantillas se usaron para renderizar la p\u00e1gina? \u00bfC\u00f3mo afecta el cach\u00e9 al rendimiento? Consultas para un Loguin Consultas para registrar un dato Consulta para visualizar datos \u00bf Donde optimizar la aplicacion web ? En casi todas las aplicaciones web din\u00e1micas el cuello de botella siempre es la base de datos ya que con frecuencia se necesita acceder a la informaci\u00f3n de los discos y realiza c\u00e1lculos costosos en la memoria para consultas complejas. Minimizar el n\u00famero de consultas como el tiempo que necesitan para ejecutarse es una forma segura de acelerar la aplicaci\u00f3n. Para lograr estos objetivos se pueden aplicar muchas modificaciones y optimizaciones sobre las consultas a las bases de datos. Para mas detalles consulte la siguiente url. Optimizacion de aplicaciones Django \u00bfQu\u00e9 es Telegraf? Telegraf es un agente de servidor basado en complementos para recopilar y enviar m\u00e9tricas y eventos de bases de datos, sistemas y sensores de IoT. Es una herramienta escrita en Go que requiere una huella de memoria minima y se compila en un \u00fanico binario sin dependencias externas. \u00bfPor qu\u00e9 utilizar Telegraf? Recopila y env\u00eda todo tipo de datos: Base de datos: con\u00e9ctese a fuentes de datos como MongoDB, MySQL, Redis y otras para recopilar y enviar m\u00e9tricas. Sistemas: recopile m\u00e9tricas de su pila moderna de plataformas, contenedores y orquestadores en la nube. Sensores de IoT: recopile datos de estado cr\u00edticos (niveles de presi\u00f3n, niveles de temperatura, etc.) de los sensores y dispositivos de IoT. Agente Telegraf puede recopilar m\u00e9tricas de una amplia gama de entradas y escribirlas en una amplia gama de salidas. Est\u00e1 impulsado por complementos tanto para la recopilaci\u00f3n como para la salida de datos, por lo que se puede ampliar f\u00e1cilmente. Est\u00e1 escrito en Go, lo que significa que es un binario compilado e independiente que se puede ejecutar en cualquier sistema sin necesidad de dependencias externas, sin necesidad de npm, pip, gem u otras herramientas de administraci\u00f3n de paquetes. Cobertura con m\u00e1s de 200 complementos, es f\u00e1cil comenzar a recopilar m\u00e9tricas de los diferentes puntos finales. Ademas, la facilidad del desarrollo de complementos significa que se pueden crear diferentes complementos que se adapten a las necesidades particulares de monitoreo. Flexible La arquitectura del complemento Telegraf admite procesos propios de la estructura de servicios implementada y no obliga a cambiar los diferentes flujos de trabajo para usar esta tecnolog\u00eda. Simplemente se adapta a la arquitectura en lugar de al rev\u00e9s. La flexibilidad de Telegraf hace que sea una decisi\u00f3n f\u00e1cil de implementar. Telegraf en nuestro proyecto A continuacion se presenta el archivo de configuracion Telegraf de forma resumida, con sus principales configuraciones y plugins: # Configuration for telegraf agent [agent] ## Default data collection interval for all inputs interval = \"10s\" ## Rounds collection interval to 'interval' ## ie, if interval=\"10s\" then always collect on :00, :10, :20, etc. round_interval = true ## Telegraf will send metrics to outputs in batches of at most ## metric_batch_size metrics. ## This controls the size of writes that Telegraf sends to output plugins. metric_batch_size = 1000 ## Maximum number of unwritten metrics per output. Increasing this value ## allows for longer periods of output downtime without dropping metrics at the ## cost of higher maximum memory usage. metric_buffer_limit = 10000 ## Collection jitter is used to jitter the collection by a random amount. ## Each plugin will sleep for a random time within jitter before collecting. ## This can be used to avoid many plugins querying things like sysfs at the ## same time, which can have a measurable effect on the system. collection_jitter = \"0s\" ## Default flushing interval for all outputs. Maximum flush_interval will be ## flush_interval + flush_jitter flush_interval = \"10s\" ## Jitter the flush interval by a random amount. This is primarily to avoid ## large write spikes for users running a large number of telegraf instances. ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s flush_jitter = \"0s\" ## By default or when set to \"0s\", precision will be set to the same ## timestamp order as the collection interval, with the maximum being 1s. ## ie, when interval = \"10s\", precision will be \"1s\" ## when interval = \"250ms\", precision will be \"1ms\" ## Precision will NOT be used for service inputs. It is up to each individual ## service input to set the timestamp at the appropriate precision. ## Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\". precision = \"\" ## Log at debug level. # debug = false ## Log only error level messages. # quiet = false ## Log target controls the destination for logs and can be one of \"file\", ## \"stderr\" or, on Windows, \"eventlog\". When set to \"file\", the output file ## is determined by the \"logfile\" setting. # logtarget = \"file\" ## Name of the file to be logged to when using the \"file\" logtarget. If set to ## the empty string then logs are written to stderr. # logfile = \"\" ## Override default hostname, if empty use os.Hostname() hostname = \"\" ## If set to true, do no set the \"host\" tag in the telegraf agent. omit_hostname = false ############################################################################### # OUTPUT PLUGINS # ############################################################################### # Configuration for sending metrics to InfluxDB [[outputs.influxdb]] ## The full HTTP or UDP URL for your InfluxDB instance. urls = [\"http://172.20.0.4:8086\"] ## The target database for metrics; will be created as needed. ## For UDP url endpoint database needs to be configured on server side. # database = \"telegraf\" database = \"telegraf\" ## If true, no CREATE DATABASE queries will be sent. Set to true when using ## Telegraf with a user without permissions to create databases or when the ## database already exists. # skip_database_creation = false skip_database_creation = false ## Name of existing retention policy to write to. Empty string writes to ## the default retention policy. Only takes effect when using HTTP. # retention_policy = \"\" retention_policy = \"\" ## The value of this tag will be used to determine the retention policy. If this ## tag is not set the 'retention_policy' option is used as the default. # retention_policy_tag = \"\" retention_policy_tag = \"\" ## Timeout for HTTP messages. # timeout = \"5s\" timeout = \"5s\" ## HTTP Basic Auth # username = \"telegraf\" # password = \"metricsmetricsmetricsmetrics\" username = \"admin\" password = \"admin\" ############################################################################### # INPUT PLUGINS # ############################################################################### # Read metrics about cpu usage [[inputs.cpu]] ## Whether to report per-cpu stats or not percpu = true ## Whether to report total system cpu stats or not totalcpu = true ## If true, collect raw CPU time metrics. collect_cpu_time = false ## If true, compute and report the sum of all non-idle CPU states. report_active = false # Read metrics about disk usage by mount point [[inputs.disk]] ## By default stats will be gathered for all mount points. ## Set mount_points will restrict the stats to only the specified mount points. # mount_points = [\"/\"] ## Ignore mount points by filesystem type. ignore_fs = [\"tmpfs\", \"devtmpfs\", \"devfs\", \"iso9660\", \"overlay\", \"aufs\", \"squashfs\"] # Read metrics about disk IO by device [[inputs.diskio]] ## By default, telegraf will gather stats for all devices including ## disk partitions. ## Setting devices will restrict the stats to the specified devices. # devices = [\"sda\", \"sdb\", \"vd*\"] ## Uncomment the following line if you need disk serial numbers. # skip_serial_number = false # ## On systems which support it, device metadata can be added in the form of ## tags. ## Currently only Linux is supported via udev properties. You can view ## available properties for a device by running: ## 'udevadm info -q property -n /dev/sda' ## Note: Most, but not all, udev properties can be accessed this way. Properties ## that are currently inaccessible include DEVTYPE, DEVNAME, and DEVPATH. # device_tags = [\"ID_FS_TYPE\", \"ID_FS_USAGE\"] # ## Using the same metadata source as device_tags, you can also customize the ## name of the device via templates. ## The 'name_templates' parameter is a list of templates to try and apply to ## the device. The template may contain variables in the form of '$PROPERTY' or ## '${PROPERTY}'. The first template which does not contain any variables not ## present for the device is used as the device name tag. ## The typical use case is for LVM volumes, to get the VG/LV name instead of ## the near-meaningless DM-0 name. # name_templates = [\"$ID_FS_LABEL\",\"$DM_VG_NAME/$DM_LV_NAME\"] # Get kernel statistics from /proc/stat [[inputs.kernel]] # no configuration # Read metrics about memory usage [[inputs.mem]] # no configuration # Get the number of processes and group them by status [[inputs.processes]] # no configuration # Read metrics about swap memory usage [[inputs.swap]] # no configuration # Read metrics about system load & uptime [[inputs.system]] ## Uncomment to remove deprecated metrics. # fielddrop = [\"uptime_format\"] ############################################################################### # SERVICE INPUT PLUGINS # ############################################################################### # # Read metrics from one or many postgresql servers [[inputs.postgresql]] address= \"host=172.20.0.8 user=postgres password=postgres dbname=postgres\" Para entender las configuraciones es necesario tomar el archivo Telegraf base y analizar cada comentario y variable dentro de las peque\u00f1as secciones separadas por [[(plugin particular)]] . Es destacable el orden que tiene el archivo y la forma en la cual esta documentado, ya que resulta bastante sencillo adaptar cada plugin a las necesidades particulares y arquitectura de red presente. El primer paso consisten en modificar la seccion [agents] ,ya que sin importan el plugin de entrada o de salida que se utilice, el agente telegraf se basara en dichas configuraciones. Luego dependiendo el tipo de servicio que se desee monitorear se configuran los INPUT PLUGINS y SERVICE INPUT PLUGINS . Para finalmente, configurar algunos parametros asociados a la base de datos a la cual se conectara telegraf para guardar las metricas adquiridas. Estas configuraciones estan en OUTPUT PLUGINS","title":"Adquisici\u00f3n de m\u00e9tricas"},{"location":"adquisicionDeMetricas/#adquisicion-de-metricas","text":"","title":"Adquisici\u00f3n de M\u00e9tricas"},{"location":"adquisicionDeMetricas/#que-es-cadvisor","text":"cAdvisor (abreviatura de c ontainer Advisor ) analiza y expone el uso de recursos y los datos de rendimiento de los contenedores en ejecuci\u00f3n. Dentro de sus principales caracter\u00edsticas podemos destacar: cAdvisor es un recopilador de uso de recursos de contenedores de c\u00f3digo abierto. Soporte nativo para contenedores Docker y solo admite otros tipos de contenedores. cAdvisor funciona por nodo. Detecta autom\u00e1ticamente todos los contenedores en el nodo dado y recopila estad\u00edsticas de uso de la CPU, la memoria, el sistema de archivos y la red. Soporte para ejecutar de forma independiente fuera de Docker o cualquier otro contenedor. Proporciona el uso general de la m\u00e1quina analizando el contenedor 'ra\u00edz' en la m\u00e1quina. Admite la exportaci\u00f3n de estad\u00edsticas a varios complementos de almacenamiento, por ejemplo, Elasticsearch, InfluxDB, etc. Las m\u00e9tricas se pueden ver en la interfaz de usuario web, /containers que exporta informaci\u00f3n en vivo sobre todos los contenedores en la m\u00e1quina. Expone estad\u00edsticas sin procesar y procesadas a trav\u00e9s de una API REST remota versionada.","title":"\u00bfQue es CAdvisor?"},{"location":"adquisicionDeMetricas/#limitaciones","text":"Recopila la utilizaci\u00f3n de recursos b\u00e1sicos, es decir, no podr\u00edamos obtener el rendimiento real de las aplicaciones de contenedor, por ejemplo, x% de utilizaci\u00f3n de CPU No ofrece capacidades de an\u00e1lisis, tendencias o almacenamiento a largo plazo.","title":"Limitaciones"},{"location":"adquisicionDeMetricas/#como-se-observa-el-panel-de-administracion-para-monitorear-las-pruebas-de-rendimiento","text":"Una vez desplegado el contenedor, podemos acceder via web a traves de https://127.0.0.1:8080 y se abrir\u00e1 una interfaz bastante sencilla e intuitiva, la cual nos va a mostrar los recursos del sistema y el listado de contendores que tenemos desplegados.","title":"\u00bfComo se observa el panel de administracion para monitorear las pruebas de rendimiento?"},{"location":"adquisicionDeMetricas/#que-es-django-debug","text":"Django Debug como su nombre lo indica, es una herramienta que permite vigilar el rendimiento de una aplicacion desarrollada en Django.Nos proporciona entre otras cosas: informaci\u00f3n de consultas de base de datos, templates usadas y tiempos de carga.","title":"\u00bfQue es Django Debug?"},{"location":"adquisicionDeMetricas/#que-es-telegraf","text":"Telegraf es un agente de servidor basado en complementos para recopilar y enviar m\u00e9tricas y eventos de bases de datos, sistemas y sensores de IoT. Es una herramienta escrita en Go que requiere una huella de memoria minima y se compila en un \u00fanico binario sin dependencias externas.","title":"\u00bfQu\u00e9 es Telegraf?"},{"location":"adquisicionDeMetricas/#por-que-utilizar-telegraf","text":"","title":"\u00bfPor qu\u00e9 utilizar Telegraf?"},{"location":"adquisicionDeMetricas/#telegraf-en-nuestro-proyecto","text":"A continuacion se presenta el archivo de configuracion Telegraf de forma resumida, con sus principales configuraciones y plugins: # Configuration for telegraf agent [agent] ## Default data collection interval for all inputs interval = \"10s\" ## Rounds collection interval to 'interval' ## ie, if interval=\"10s\" then always collect on :00, :10, :20, etc. round_interval = true ## Telegraf will send metrics to outputs in batches of at most ## metric_batch_size metrics. ## This controls the size of writes that Telegraf sends to output plugins. metric_batch_size = 1000 ## Maximum number of unwritten metrics per output. Increasing this value ## allows for longer periods of output downtime without dropping metrics at the ## cost of higher maximum memory usage. metric_buffer_limit = 10000 ## Collection jitter is used to jitter the collection by a random amount. ## Each plugin will sleep for a random time within jitter before collecting. ## This can be used to avoid many plugins querying things like sysfs at the ## same time, which can have a measurable effect on the system. collection_jitter = \"0s\" ## Default flushing interval for all outputs. Maximum flush_interval will be ## flush_interval + flush_jitter flush_interval = \"10s\" ## Jitter the flush interval by a random amount. This is primarily to avoid ## large write spikes for users running a large number of telegraf instances. ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s flush_jitter = \"0s\" ## By default or when set to \"0s\", precision will be set to the same ## timestamp order as the collection interval, with the maximum being 1s. ## ie, when interval = \"10s\", precision will be \"1s\" ## when interval = \"250ms\", precision will be \"1ms\" ## Precision will NOT be used for service inputs. It is up to each individual ## service input to set the timestamp at the appropriate precision. ## Valid time units are \"ns\", \"us\" (or \"\u00b5s\"), \"ms\", \"s\". precision = \"\" ## Log at debug level. # debug = false ## Log only error level messages. # quiet = false ## Log target controls the destination for logs and can be one of \"file\", ## \"stderr\" or, on Windows, \"eventlog\". When set to \"file\", the output file ## is determined by the \"logfile\" setting. # logtarget = \"file\" ## Name of the file to be logged to when using the \"file\" logtarget. If set to ## the empty string then logs are written to stderr. # logfile = \"\" ## Override default hostname, if empty use os.Hostname() hostname = \"\" ## If set to true, do no set the \"host\" tag in the telegraf agent. omit_hostname = false ############################################################################### # OUTPUT PLUGINS # ############################################################################### # Configuration for sending metrics to InfluxDB [[outputs.influxdb]] ## The full HTTP or UDP URL for your InfluxDB instance. urls = [\"http://172.20.0.4:8086\"] ## The target database for metrics; will be created as needed. ## For UDP url endpoint database needs to be configured on server side. # database = \"telegraf\" database = \"telegraf\" ## If true, no CREATE DATABASE queries will be sent. Set to true when using ## Telegraf with a user without permissions to create databases or when the ## database already exists. # skip_database_creation = false skip_database_creation = false ## Name of existing retention policy to write to. Empty string writes to ## the default retention policy. Only takes effect when using HTTP. # retention_policy = \"\" retention_policy = \"\" ## The value of this tag will be used to determine the retention policy. If this ## tag is not set the 'retention_policy' option is used as the default. # retention_policy_tag = \"\" retention_policy_tag = \"\" ## Timeout for HTTP messages. # timeout = \"5s\" timeout = \"5s\" ## HTTP Basic Auth # username = \"telegraf\" # password = \"metricsmetricsmetricsmetrics\" username = \"admin\" password = \"admin\" ############################################################################### # INPUT PLUGINS # ############################################################################### # Read metrics about cpu usage [[inputs.cpu]] ## Whether to report per-cpu stats or not percpu = true ## Whether to report total system cpu stats or not totalcpu = true ## If true, collect raw CPU time metrics. collect_cpu_time = false ## If true, compute and report the sum of all non-idle CPU states. report_active = false # Read metrics about disk usage by mount point [[inputs.disk]] ## By default stats will be gathered for all mount points. ## Set mount_points will restrict the stats to only the specified mount points. # mount_points = [\"/\"] ## Ignore mount points by filesystem type. ignore_fs = [\"tmpfs\", \"devtmpfs\", \"devfs\", \"iso9660\", \"overlay\", \"aufs\", \"squashfs\"] # Read metrics about disk IO by device [[inputs.diskio]] ## By default, telegraf will gather stats for all devices including ## disk partitions. ## Setting devices will restrict the stats to the specified devices. # devices = [\"sda\", \"sdb\", \"vd*\"] ## Uncomment the following line if you need disk serial numbers. # skip_serial_number = false # ## On systems which support it, device metadata can be added in the form of ## tags. ## Currently only Linux is supported via udev properties. You can view ## available properties for a device by running: ## 'udevadm info -q property -n /dev/sda' ## Note: Most, but not all, udev properties can be accessed this way. Properties ## that are currently inaccessible include DEVTYPE, DEVNAME, and DEVPATH. # device_tags = [\"ID_FS_TYPE\", \"ID_FS_USAGE\"] # ## Using the same metadata source as device_tags, you can also customize the ## name of the device via templates. ## The 'name_templates' parameter is a list of templates to try and apply to ## the device. The template may contain variables in the form of '$PROPERTY' or ## '${PROPERTY}'. The first template which does not contain any variables not ## present for the device is used as the device name tag. ## The typical use case is for LVM volumes, to get the VG/LV name instead of ## the near-meaningless DM-0 name. # name_templates = [\"$ID_FS_LABEL\",\"$DM_VG_NAME/$DM_LV_NAME\"] # Get kernel statistics from /proc/stat [[inputs.kernel]] # no configuration # Read metrics about memory usage [[inputs.mem]] # no configuration # Get the number of processes and group them by status [[inputs.processes]] # no configuration # Read metrics about swap memory usage [[inputs.swap]] # no configuration # Read metrics about system load & uptime [[inputs.system]] ## Uncomment to remove deprecated metrics. # fielddrop = [\"uptime_format\"] ############################################################################### # SERVICE INPUT PLUGINS # ############################################################################### # # Read metrics from one or many postgresql servers [[inputs.postgresql]] address= \"host=172.20.0.8 user=postgres password=postgres dbname=postgres\" Para entender las configuraciones es necesario tomar el archivo Telegraf base y analizar cada comentario y variable dentro de las peque\u00f1as secciones separadas por [[(plugin particular)]] . Es destacable el orden que tiene el archivo y la forma en la cual esta documentado, ya que resulta bastante sencillo adaptar cada plugin a las necesidades particulares y arquitectura de red presente. El primer paso consisten en modificar la seccion [agents] ,ya que sin importan el plugin de entrada o de salida que se utilice, el agente telegraf se basara en dichas configuraciones. Luego dependiendo el tipo de servicio que se desee monitorear se configuran los INPUT PLUGINS y SERVICE INPUT PLUGINS . Para finalmente, configurar algunos parametros asociados a la base de datos a la cual se conectara telegraf para guardar las metricas adquiridas. Estas configuraciones estan en OUTPUT PLUGINS","title":"Telegraf en nuestro proyecto"},{"location":"generacionDeTrafico/","text":"Generaci\u00f3n de tr\u00e1fico \u00bfQu\u00e9 es Locust? Locust es una herramienta de prueba de carga de usuario distribuida y f\u00e1cil de usar. Est\u00e1 dise\u00f1ado para sitios web de prueba de carga (u otros sistemas) y para determinar cu\u00e1ntos usuarios simult\u00e1neos puede manejar un sistema. La idea es que, durante una prueba, un \"enjambre de langostas\" ataque el sitio web. El comportamiento de cada langosta (o usuario de prueba, si lo desea) se lo puede definir y el proceso de enjambre se supervisa desde una interfaz de usuario web en tiempo real. Esto ayudar\u00e1 a luchar contra las pruebas e identificar los cuellos de botella en el c\u00f3digo antes de permitir la entrada a usuarios reales. Como poner en marcha r\u00e1pidamente Requerimientos previos A continuaci\u00f3n, se adjuntan un conjunto de requisitos para inicializar Locust. Las versiones no son requerimientos excluyentes en todos los casos. Se recomienda respetar en cualquier caso la versi\u00f3n del sistema operativo y una version de Python 3.x. 1 - Sistema operativo Linux. Versi\u00f3n: 18.04.3 2- Python instalado. Versi\u00f3n: 3.6.8 3- Docker instalado. Versi\u00f3n: 19.3.11 Procedimiento 1- Cree una carpeta de trabajo donde levantar Locust. 2- Dentro del directorio, crear un archivo de configuraci\u00f3n Locust denominado \"locustfile.py\". 3- Genere la configuraci\u00f3n de las pruebas de performance en dicho archivo considerando la documentaci\u00f3n oficial. 4- Ejecute el siguiente comando docker con una terminal dentro de la carpeta de trabajo. docker run -p 8089:8089 -v $PWD:/mnt/locust locustio/locust -f /mnt/locust/locustfile.py \u00bfC\u00f3mo se interpreta el comando? En primer lugar, \"docker run\" levantar\u00e1 un contenedor con la imagen locustio/locust . Adem\u00e1s, Tener en cuenta que las especificaciones \"-p (puert.Host:puert.Cont)\" expondr\u00e1n los puertos 8089 del contenedor, en los puertos del host 8089. Luego, \"-v (direct.Host):(direct.Cont)\" determina que se realizar\u00e1 una copia del directorio del host dentro de una ubicaci\u00f3n en el contenedor, esto genera que las modificaciones en tiempo real de los archivos en el directorio del host, cambien directamente los archivos dentro del contenedor. De esta forma $PWD, est\u00e1 indicando la ubicaci\u00f3n actual de trabajo que se copiar\u00e1 dentro de la direcci\u00f3n /mnt/locust del contenedor. La fracci\u00f3n del comando que realiza dicha tarea es \"-v $PWD:/mnt/locust\". Por \u00faltimo, como el archivo \"locustfile.py\" estaba en la carpeta de trabajo, se habr\u00e1 copiado dentro del contenedor en la direcci\u00f3n /mnt/locust, por lo que habr\u00e1 que especificar que el archivo de pruebas de performance para Locust se encuentra en \"/mnt/locust/locustfile.py\". Esto se realiza con la \u00faltima parte del comando \"-f /mnt/locust/locustfile.py\". Comenzando con las pruebas Prueba b\u00e1sica: Consulta a servidor Para comenzar a realizar testing de tr\u00e1fico mediante el uso de Locust, tiene sentido comenzar por una prueba bien b\u00e1sica como la se comentar\u00e1 a continuaci\u00f3n. En este apartado, mediante el c\u00f3digo inicial \"basicTest_locust.py\" que se encuentra en la carpeta \"desarrollo/Generacion de trafico\" de este mismo proyecto, se realizan consultas al servidor de inter\u00e9s con la finalidad de garantizar nuestra llegada hasta la direcci\u00f3n indicada tanto mediante la visualizaci\u00f3n desde la p\u00e1gina de Locust como del terminal del servidor. from locust import HttpUser, task, between class WebsiteUser(HttpUser): wait_time = between(1,2) @task def index(self): self.client.get(\"/\") En el c\u00f3digo presentado se puede observar la importaci\u00f3n de la clase \"HttpUser\" para que los usuarios puedan realizar solicitudes Http, adem\u00e1s se importa \"task\" para asignar las distintas tareas a realizar y finalmente \"between()\" que definir\u00e1 cada cuanto tiempo se ejecutar\u00e1n las distintas tareas \"@task\". Luego se crea la clase \"WebsiteUser\", en donde se define la tarea \"index\"que realizar\u00e1 el usuario designado. En este caso lo \u00fanico que ser\u00e1 es realizar un \"get\" hacia la p\u00e1gina inicial, que en este caso ser\u00eda hacia nuestro servidor al cual se llega mediante la asignaci\u00f3n de la direcci\u00f3n ip desde la p\u00e1gina o servidor de Locust. Por \u00faltimo, para poder correr este script y mediante un terminal ubicado en la misma carpeta que contiene al archivo \"basicTest_locust.py\" se debe de ejecutar el siguiente comando: docker run -p 8089:8089 -v $PWD:/mnt/locust locustio/locust -f /mnt/locust/basicTest_locust.py Una vez que se inicializa Locust y queda estable. Se debe acceder mediante el navegador web a la direcci\u00f3n: 'http://127.0.0.1:8089' Locust en nuestro proyecto Locust como servicio generador de trafico, se ejecuta en una estructura dockerizada. Como se puede ver a continuacion, tiene dedicada una porcion de codigo en el archivo docker-compose.yml: locust: build: ScriptLocust command: -f /mnt/locust/Test_locust_regUser_08-11-2020.py volumes: - ./ScriptLocust:/mnt/locust ports: - \"8089:8089\" links: - web:web networks: red_servicios: ipv4_address: 172.21.0.3 container_name: Locust_SQlite Lo mas importante es que una vez construido el contenedor y montada la carpeta ScriptLocust dentro del mismo en la direccion mnt/locust , se ejecuta command, lo que indica que debe correr el servicio utilizando como script Test_locust_regUser_08-11-2020.py Script para pruebas de performance A nivel general, puede decirse que hay dos tipos de usuarios. Sensores y consumidores. El primer grupo tiene un comportamiento muy caracteristico de acuerdo al tipo de dato adquirido y la frecuencia de actualizacion sobre el servidor web. Mientras que el segundo grupo puede ser modelado a partir de las necesidades de consumo de dichos datos. De esta forma, resulta distinto analizar un escenario donde los sensores estan capturando variables asociadas al clima y los consumidores no tienen apuro en adquirir dichos datos, que aquellos escenarios donde los sensores manipulan variables criticas en tiempo real y existen consumidores realizando consultas practicamente todo el tiempo. Este trabajo va orienta al primer ejemplo, donde las variables no son criticas y no se necesitan segundo a segundo pero existe un volumen de trafico significativo dada la cantidad de sensores y consumidores.Los datos de los sensores son temperatura , presion y humedad y la frecuencia con la que se cargan en el servidor web corresponde a intervalos regulares de tiempo de 15 min \u00bfTiene logica? Los datos de los sensores no cambiaran significativamente durante intervalos regulares de tiempo inferiores a 15 minutos, por lo tanto no tiene sentido plantear un escenario donde la carga sea inferior a dicho valor. Ademas, esta periodicidad temporal implicaria la utilizacion de la frecuencia mas alta de carga de datos dentro de un rango temporal de 1 hora, por lo que resultaria una prueba critica para el servidor. En cuanto al comportamiento de los consumidores, se plantea que cada uno de ellos consulta los datos administrados en el sitio web y previamente cargados por los sensores en las bases de datos, en intervalos regulares de tiempo comprendidos entre 2 a 3 minutos, siempre con un valor aleatorio de consulta a consulta. Al analizar el script encontramos en las primeras lineas la funcion obt_cred: def obt_cred(nombre_archivo,cant_user): print(\"*************************************************\") print(\".............Procesando Credenciales.............\") print(\"*************************************************\") indice = list(range(0, 2 * cant_user - 1, 2)) f = open(nombre_archivo, \"r\") List_prep = f.readline().replace(\"[\", \"\").replace(\"'\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"]\",\"\").split(\",\") Credenciales = [] for j in indice: Credenciales.append(((List_prep[j].strip(),List_prep[j + 1].strip()))) return Credenciales namefile=\"/mnt/locust/usuarios.txt\" cantidad_usuarios=1000 Esta funcion permite preparar al script locust para generar las credenciales de cada usuario en formato lista mediante tuplas [(\"usuario\",\"contrase\u00f1a\"),(,)...] que posteriormente usaran las diferentes instancias (\" Hilos de Locust \"). Como puede apreciarse en la porcion de codigo presentada anteriormente, los diferentes usuarios y contrase\u00f1as se encuentran en un archivo de texto que resulta ser argumento de entrada de la funcion, junto con la cantidad de usuarios. La siguiente funcion resulta de vital importancia, ya que definira la conexion entre el servicio locust e influxdb como base de datos de series temporales para dar persistencia en el tiempo a las metricas. hostIP_str=\"172.21.0.4\" #ip apuntando a influx port_str=\"8086\" username_str=\"admin\" passw_str=\"admin\" database_str=\"influx\" hostname = socket.gethostname() client = InfluxDBClient(hostIP_str,port_str,username_str,passw_str,database_str) @events.request_success.add_listener def individual_success_handle(request_type, name, response_time, response_length, **kwargs): SUCCESS_TEMPLATE = '[{\"measurement\": \"%s\",\"tags\": {\"hostname\":\"%s\",\"requestName\": \"%s\",\"requestType\": \"%s\",\"status\":\"%s\"},\"time\":\"%s\",\"fields\": {\"responseTime\": \"%s\",\"responseLength\":\"%s\"}}]' json_string = SUCCESS_TEMPLATE % (\"ResponseTable\", hostname, name, request_type, \"success\", datetime.datetime.now(tz=pytz.UTC), response_time, response_length) client.write_points(json.loads(json_string), time_precision='ms') @events.request_failure.add_listener def individual_fail_handle(request_type, name, response_time, response_length, exception, **kwargs): FAIL_TEMPLATE = '[{\"measurement\": \"%s\",\"tags\": {\"hostname\":\"%s\",\"requestName\": \"%s\",\"requestType\": \"%s\",\"exception\":\"%s\",\"status\":\"%s\"},\"time\":\"%s\",\"fields\": {\"responseTime\": \"%s\",\"responseLength\":\"%s\"}}]' json_string = FAIL_TEMPLATE % (\"ResponseTable\", hostname, name, request_type, exception, \"fail\", datetime.datetime.now(tz=pytz.UTC), response_time, response_length) client.write_points(json.loads(json_string), time_precision='ms') En primer lugar se definen variables como direccion ip y puerto donde se encuentra funcionando Influxdb, asi como tambien nombre de la base de datos, usuario y contrase\u00f1a para posteriormente crear una conexion e incorporar dos eventos a la escucha. Estos eventos saltan cuando locust tiene respuesta a las peticiones que generan cada uno de los hilos (usuarios). Ante respuestas exitosas, request_success se hace cargo de generar una escritura en influxdb en la medida \"ResponseTable\" que tendra como secciones: hostname requestName requestType status time fields responseTime (tiempo de respuesta) , responseLength (Longitud de la respuesta) De la misma forma ocurre con aquellas respuestas que acusan algun tipo de fallo. En esta situacion, el evento a la escucha que se encargara de la escritura es request_failure Luego se definen las clases y sus tareas, asi como tambien los tiempos de espera entre ejecucion de tareas de cada hilo y la preferencia de eleccion entre ellas. Todo esto determina el comportamiento de cada hilo o como comunmente definimos nosotros \"usuarios\". Es posible modelar de forma distinta cada clase haciendo uso puramente y esclusivamente de python, lo que permite hacer una infinidad de modelos y pruebas de rendimiento interesantes. class UserSensor(HttpUser): wait_time = constant_pacing (900) weight = 1 @task def login_register_logout(self): print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\") print(\"Realizando:__ Login Register Logout__\") print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\") usuario,contrase\u00f1a,estado=self.login(Credenciales) if estado ==1: self.register_date() self.logout(usuario,contrase\u00f1a) def login(self,Credenciales): print(\"______________Proceso de Login_____________\") status=0 if len(Credenciales) > 0: user,password=Credenciales.pop() respuesta = self.client.get(\"/accounts/login/\") if respuesta.status_code==200: csrftoken = respuesta.cookies['csrftoken'] respuesta_1=self.client.post(\"/accounts/login/\", {'username': user, 'password': password},headers={'X-CSRFToken': csrftoken}) if respuesta_1.status_code==200: print(\"____________Exito Login_________________\") status=1 else: print(\"____________Falla Login _________________\") Credenciales.append((user, password)) else: print(\"____________ Falla Login al ingresar a la pagina_________________\") Credenciales.append((user, password)) else: print(\"No hay credencial disponible\") user=\"\" password=\"\" return user,password,status La clase presentada en la seccion de codigo anterior, hereda las caracteristicas de la clase HttpUser, ya que con esta ultima resulta mucho mas simple mantener secciones abiertas para lograr login, post y demas. Se denomina Usersensor y tiene una unica tarea definida como login_register_logout que como su nombre lo indica, tiene como finalidad, generar un registro de un dato por parte de un sensor luego de un login y finalizar con un logout, para liberar la conexion. Luego de finalizar la tarea, el hilo duerme un periodo de tiempo necesario para completar un ciclo de 15 minutos y posteriormente se activa para ejecutar nuevamente la tarea en cuestion. Si los tiempos de ejecucion del hilo superan los 15 minutos y aun no finalizo, se lanza otra instancia, acumulando de esta forma hilos simultaneos. A pesar de parecer complejo ,el funcionamiento de la tarea es bastante sencillo. @task def login_register_logout(self): print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\") print(\"Realizando:__ Login Register Logout__\") print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\") usuario,contrase\u00f1a,estado=self.login(Credenciales) if estado ==1: self.register_date() self.logout(usuario,contrase\u00f1a) Primero se muestra un mensaje por consola para tener conocimiento que se esta ejecutando la tarea. Luego se ejecuta la funcion login a partir de la instancia actual, pasando como argumento la lista con tuplas que contienen usuario y contrase\u00f1a disponibles para dicha instancia. Independientemente del resultado del proceso (exito o falla), la funcion devuelve tres variables en una forma u otra. El usuario y contrase\u00f1a que lograron acceder al servidor web como string y el estado de la conexion en uno, en el caso de ser exitoso y el usuario y contrase\u00f1a como string vacios junto con estado cero si fallo. La variable estado es fundamental porque dependiendo su valor, se determinara si se ejecutaran las demas funciones o si el hilo finaliza alli. Como puede observase, la tarea esta compuesta de tres funciones: login , register_date y logout . La primera de ellas ya fue presentada, lo que nos lleva a la funcion register_date def register_date(self): print(\"_________Subiendo Datos_________\") ubc_var = ['RC', 'SAM', 'GD'] ubc_selec = random.randint(0, 2) dat_var_num = [random.randint(-10, 50-1), random.randint(880, 1080-1), random.randint(0, 100-1)] csftoken=self.client.get(\"/registro/ingresar\").cookies['csrftoken'] posteo=self.client.post(\"/registro/privado\", {'ubicacion':ubc_var[ubc_selec],'temperatura':dat_var_num[0],'presion':dat_var_num[1],'humedad':dat_var_num[2]},headers={'X-CSRFToken': csftoken}) if (posteo.status_code == 200): print(\"_______Exito en la subida de datos ____________\") else: print(\"_____________Fallo el registro de datos______________\") Esta funcion, genera un vector con las tres variables a cargar en la base de datos, generadas de forma a aleatoria en los rangos (-10,49) para temperatura, (880,1079) para presion,(0,99) para humedad. Posteriormente , selecciona una ubicacion al azar entre RC , SAM y GD y arma la solicitud para realizar un POST. Por ultimo la funcion Logout se asegura de finalizar la conexion del usuario y devolver las credenciales utilizadas para que otro proceso pueda volver a tomarlas. def logout(self,user,password): print(\"______________Proceso de Logout____________\") respuesta=self.client.get(\"/accounts/logout/\") while (respuesta.status_code != 200): print(\" __________Intentando nuevamente logout________ \") respuesta = self.client.get(\"/accounts/logout/\") print(\"-----------------Logout exitoso---------------\") Credenciales.append((user, password)) La segunda clase denominada UserCons tiene dos tareas definidas como consultaindex y consultabasedatos . La primera tarea solamente realiza un GET al index de la pagina web y la segunda realiza un POST para consultar datos. Ambas tienen igual probabilidad de ejecutarse al crearse un nuevo hilo. class UserCons(HttpUser): wait_time = between(120,360) weight = 3 @task def consultaindex(self): print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\") print(\"Realizando:__consultaIndex__\") print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\") self.client.get(\"/\") @task def consultabasedatos(self): print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\") print(\"Realizando:__Consulta Base de Datos__\") print(\"-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\") ubc_var = ['RC', 'SAM', 'GD'] list_ubic=[] ubc_cant=random.randint(1,3) ubc = random.randint(0, 2) if ubc_cant == 1: list_ubic.append(ubc_var[ubc]) elif ubc_cant == 2: list_ubic.append(ubc_var[ubc]) ubc1=random.randint(0,2) while (ubc1 == ubc ): ubc1=random.randint(0, 2) list_ubic.append(ubc_var[ubc1]) else: list_ubic=ubc_var dat_var = ['TEMP', 'PRE', 'HUM'] list_dato=[] dat_cant=random.randint(1,3) dat = random.randint(0, 2) if dat_cant == 1: list_dato.append(dat_var[dat]) elif dat_cant == 2: list_dato.append(dat_var[dat]) dat1=random.randint(0,2) while (dat1 == dat ): dat1=random.randint(0, 2) list_dato.append(dat_var[dat1]) else: list_dato=dat_var cookies=self.client.get(\"/registro/procUser\").cookies['csrftoken'] self.client.post(\"/registro/procUser\",{'SelecUbic':list_ubic,'SelecDato':list_dato},headers={'X-CSRFToken':cookies}) La ultima tarea presentada parece ser algo compleja pero solamente esta construyendo una consulta al servidor web mediante metodo POST teniendo como referencia el formato de formulario presentado por django. Para que la solicitud sea considerada valida debe tener al menos un elemento identificable tanto en SelecUbic como en SelecDato dentro del set de posibilidades y debe ser presentado en formato lista. Entiendase un vector para SelecUbic con uno o mas valores dentro de las posibilidades ( RC,SAM,GD ) y lo mismo para SelecDato pero con valores como ( TEMP,PRE,HUM ). El codigo tiene un poco mas de logica porque la construccion parte de procesos aleatorios. Estos ultimos, permiten que cada solictud sea diferente a la anterior, permitiendo generar diferentes cargas de trafico, ya que no seria lo mismo solicitar unicamente la temperatura de sampacho que pedir temperatura, presion y humedad tanto para rio cuarto, sampacho y general deheza. De esta manera, se generan un avanico de posibles solicitudes dadas la cantidad de valores diferentes que tiene cada variable y todas las posibles combinaciones que pueden ser generadas.","title":"Generaci\u00f3n de tr\u00e1fico"},{"location":"generacionDeTrafico/#generacion-de-trafico","text":"","title":"Generaci\u00f3n de tr\u00e1fico"},{"location":"generacionDeTrafico/#que-es-locust","text":"Locust es una herramienta de prueba de carga de usuario distribuida y f\u00e1cil de usar. Est\u00e1 dise\u00f1ado para sitios web de prueba de carga (u otros sistemas) y para determinar cu\u00e1ntos usuarios simult\u00e1neos puede manejar un sistema. La idea es que, durante una prueba, un \"enjambre de langostas\" ataque el sitio web. El comportamiento de cada langosta (o usuario de prueba, si lo desea) se lo puede definir y el proceso de enjambre se supervisa desde una interfaz de usuario web en tiempo real. Esto ayudar\u00e1 a luchar contra las pruebas e identificar los cuellos de botella en el c\u00f3digo antes de permitir la entrada a usuarios reales.","title":"\u00bfQu\u00e9 es Locust?"},{"location":"generacionDeTrafico/#como-poner-en-marcha-rapidamente","text":"","title":"Como poner en marcha r\u00e1pidamente"},{"location":"generacionDeTrafico/#requerimientos-previos","text":"A continuaci\u00f3n, se adjuntan un conjunto de requisitos para inicializar Locust. Las versiones no son requerimientos excluyentes en todos los casos. Se recomienda respetar en cualquier caso la versi\u00f3n del sistema operativo y una version de Python 3.x. 1 - Sistema operativo Linux. Versi\u00f3n: 18.04.3 2- Python instalado. Versi\u00f3n: 3.6.8 3- Docker instalado. Versi\u00f3n: 19.3.11","title":"Requerimientos previos"},{"location":"generacionDeTrafico/#procedimiento","text":"1- Cree una carpeta de trabajo donde levantar Locust. 2- Dentro del directorio, crear un archivo de configuraci\u00f3n Locust denominado \"locustfile.py\". 3- Genere la configuraci\u00f3n de las pruebas de performance en dicho archivo considerando la documentaci\u00f3n oficial. 4- Ejecute el siguiente comando docker con una terminal dentro de la carpeta de trabajo. docker run -p 8089:8089 -v $PWD:/mnt/locust locustio/locust -f /mnt/locust/locustfile.py \u00bfC\u00f3mo se interpreta el comando? En primer lugar, \"docker run\" levantar\u00e1 un contenedor con la imagen locustio/locust . Adem\u00e1s, Tener en cuenta que las especificaciones \"-p (puert.Host:puert.Cont)\" expondr\u00e1n los puertos 8089 del contenedor, en los puertos del host 8089. Luego, \"-v (direct.Host):(direct.Cont)\" determina que se realizar\u00e1 una copia del directorio del host dentro de una ubicaci\u00f3n en el contenedor, esto genera que las modificaciones en tiempo real de los archivos en el directorio del host, cambien directamente los archivos dentro del contenedor. De esta forma $PWD, est\u00e1 indicando la ubicaci\u00f3n actual de trabajo que se copiar\u00e1 dentro de la direcci\u00f3n /mnt/locust del contenedor. La fracci\u00f3n del comando que realiza dicha tarea es \"-v $PWD:/mnt/locust\". Por \u00faltimo, como el archivo \"locustfile.py\" estaba en la carpeta de trabajo, se habr\u00e1 copiado dentro del contenedor en la direcci\u00f3n /mnt/locust, por lo que habr\u00e1 que especificar que el archivo de pruebas de performance para Locust se encuentra en \"/mnt/locust/locustfile.py\". Esto se realiza con la \u00faltima parte del comando \"-f /mnt/locust/locustfile.py\".","title":"Procedimiento"},{"location":"generacionDeTrafico/#comenzando-con-las-pruebas","text":"","title":"Comenzando con las pruebas"},{"location":"generacionDeTrafico/#prueba-basica-consulta-a-servidor","text":"Para comenzar a realizar testing de tr\u00e1fico mediante el uso de Locust, tiene sentido comenzar por una prueba bien b\u00e1sica como la se comentar\u00e1 a continuaci\u00f3n. En este apartado, mediante el c\u00f3digo inicial \"basicTest_locust.py\" que se encuentra en la carpeta \"desarrollo/Generacion de trafico\" de este mismo proyecto, se realizan consultas al servidor de inter\u00e9s con la finalidad de garantizar nuestra llegada hasta la direcci\u00f3n indicada tanto mediante la visualizaci\u00f3n desde la p\u00e1gina de Locust como del terminal del servidor. from locust import HttpUser, task, between class WebsiteUser(HttpUser): wait_time = between(1,2) @task def index(self): self.client.get(\"/\") En el c\u00f3digo presentado se puede observar la importaci\u00f3n de la clase \"HttpUser\" para que los usuarios puedan realizar solicitudes Http, adem\u00e1s se importa \"task\" para asignar las distintas tareas a realizar y finalmente \"between()\" que definir\u00e1 cada cuanto tiempo se ejecutar\u00e1n las distintas tareas \"@task\". Luego se crea la clase \"WebsiteUser\", en donde se define la tarea \"index\"que realizar\u00e1 el usuario designado. En este caso lo \u00fanico que ser\u00e1 es realizar un \"get\" hacia la p\u00e1gina inicial, que en este caso ser\u00eda hacia nuestro servidor al cual se llega mediante la asignaci\u00f3n de la direcci\u00f3n ip desde la p\u00e1gina o servidor de Locust. Por \u00faltimo, para poder correr este script y mediante un terminal ubicado en la misma carpeta que contiene al archivo \"basicTest_locust.py\" se debe de ejecutar el siguiente comando: docker run -p 8089:8089 -v $PWD:/mnt/locust locustio/locust -f /mnt/locust/basicTest_locust.py Una vez que se inicializa Locust y queda estable. Se debe acceder mediante el navegador web a la direcci\u00f3n: 'http://127.0.0.1:8089'","title":"Prueba b\u00e1sica: Consulta a servidor"},{"location":"generacionDeTrafico/#locust-en-nuestro-proyecto","text":"Locust como servicio generador de trafico, se ejecuta en una estructura dockerizada. Como se puede ver a continuacion, tiene dedicada una porcion de codigo en el archivo docker-compose.yml: locust: build: ScriptLocust command: -f /mnt/locust/Test_locust_regUser_08-11-2020.py volumes: - ./ScriptLocust:/mnt/locust ports: - \"8089:8089\" links: - web:web networks: red_servicios: ipv4_address: 172.21.0.3 container_name: Locust_SQlite Lo mas importante es que una vez construido el contenedor y montada la carpeta ScriptLocust dentro del mismo en la direccion mnt/locust , se ejecuta command, lo que indica que debe correr el servicio utilizando como script Test_locust_regUser_08-11-2020.py","title":"Locust en nuestro proyecto"},{"location":"generacionDeTrafico/#script-para-pruebas-de-performance","text":"A nivel general, puede decirse que hay dos tipos de usuarios. Sensores y consumidores. El primer grupo tiene un comportamiento muy caracteristico de acuerdo al tipo de dato adquirido y la frecuencia de actualizacion sobre el servidor web. Mientras que el segundo grupo puede ser modelado a partir de las necesidades de consumo de dichos datos. De esta forma, resulta distinto analizar un escenario donde los sensores estan capturando variables asociadas al clima y los consumidores no tienen apuro en adquirir dichos datos, que aquellos escenarios donde los sensores manipulan variables criticas en tiempo real y existen consumidores realizando consultas practicamente todo el tiempo. Este trabajo va orienta al primer ejemplo, donde las variables no son criticas y no se necesitan segundo a segundo pero existe un volumen de trafico significativo dada la cantidad de sensores y consumidores.Los datos de los sensores son temperatura , presion y humedad y la frecuencia con la que se cargan en el servidor web corresponde a intervalos regulares de tiempo de 15 min","title":"Script para pruebas de performance"},{"location":"informacion/","text":"Informaci\u00f3n \u00bfComo ejecutar el proyecto? Al descargar la carpeta correspondiente al proyecto, presente en el repositorio \"Versiones Finales\", debemos abrir una consola de comandos en la raiz del mismo, precisamente donde se encuentra el archivo docker-compose.yml y ejecutar: docker-compose up Este simple comando llevara a cabo una serie de instrucciones predefinidas que levantaran automaticamente entre 7 a 9 servicios, dependiendo de la base de datos que se este utilizando. Estos servicios son: Django en la siguiente ubicacion: 172.2x.0.2:8010 Locust en la siguiente ubicacion: 172.2x.0.3:8089 Influxdb en la siguiente ubicacion: 172.2x.0.4:8086 Chronograf en la siguiente ubicacion: 172.2x.0.5:8888 Grafana en la siguiente ubicacion: 172.2x.0.6:3000 cAdvisor en la siguiente ubicacion: 172.2x.0.7:8080 PostgreSQL (opcional) en el caso de estar usando esta db: 172.20.0.8 Telegraf (opcional) en la siguiente ubicacion: 172.20.0.9 Reporter en la siguiente ubicacion: 172.2x.0.10:8686 Como puede observarse, todos los contenedores pertenecen a la misma red interna \"172.2x.0.0/16\" (en donde la 'x' sera 0 si se usa PostgreSQL o 1 si se usa Sqlite3) y son capaces de comunicarse bajo cualquier arquitectura de red sobre la cual se levante. Con respecto al ultimo servicio, \"Reporter\", tiene unicamente la tarea de importar las metricas de Grafana a PDF. Para comprender mas en detalle como es que interactuan entre si los distintos servicios se debe de observar la siguiente figura: Esta portabilidad de la estructura entera es gracias a los beneficios que aporta Docker Compose a la tecnologia Docker, ya que Docker Compose es una herramienta que permite simplificar el uso de Docker. A partir de archivos YAML es mas sencillo crear contendores, conectarlos, habilitar puertos, volumenes, etc. Con Compose se puede crear diferentes contenedores y al mismo tiempo, en cada contenedor, diferentes servicios, unirlos a un vol\u00famen com\u00fan, iniciarlos y apagarlos, etc. Es un componente fundamental para poder construir aplicaciones y microservicios. En vez de utilizar Docker via una serie inmemorizable de comandos bash y scripts, Docker Compose permite mediante archivos YAML, poder instruir al Docker Engine a realizar tareas, preprogramadas. Y esta es la clave, la facilidad para dar una serie de instrucciones, y luego repetirlas en diferentes ambientes. A continuacion se hara una descripcion del archivo para la implementacion con SQlite: version: '3.2' services: web: build: appTrafico command: python manage.py runserver 172.21.0.2:8010 volumes: - ./appTrafico:/TraficoGyL ports: - \"8010:8010\" networks: red_servicios: ipv4_address: 172.21.0.2 container_name: Django_SQlite locust: build: ScriptLocust command: -f /mnt/locust/Test_locust_regUser_08-11-2020.py volumes: - ./ScriptLocust:/mnt/locust ports: - \"8089:8089\" links: - web:web networks: red_servicios: ipv4_address: 172.21.0.3 container_name: Locust_SQlite influxdb: build: influxdb env_file: configuration.env ports: - '8086:8086' volumes: - influxdb_data:/var/lib/influxdb networks: red_servicios: ipv4_address: 172.21.0.4 container_name: Influxdb_SQlite chronograf: image: chronograf:1.5 volumes: - chronograf_data:/var/lib/chronograf ports: - '8087:8888' networks: red_servicios: ipv4_address: 172.21.0.5 container_name: Chronograf_SQlite grafana: build: grafana env_file: configuration.env links: - influxdb ports: - '3000:3000' volumes: - grafana_data:/var/lib/grafana - ./grafana/dashboard:/var/lib/grafana/dashboards networks: red_servicios: ipv4_address: 172.21.0.6 container_name: Grafana_SQlite reporter: image: izakmarais/grafana-reporter:${gr_version:-latest} command: \"-ip 172.21.0.6:3000\" ports: - \"8686:8686\" networks: red_servicios: ipv4_address: 172.21.0.10 container_name: Reporter_Grafana_SQlite cadvisor: image: google/cadvisor command: -storage_driver=influxdb -storage_driver_db=influx -storage_driver_host=172.21.0.4:8086 ports: - \"8080:8080\" volumes: - /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro links: - influxdb:influxdb privileged: true networks: red_servicios: ipv4_address: 172.21.0.7 container_name: cAdvisor_SQlite networks: red_servicios: driver: bridge ipam: config: - subnet: 172.21.0.0/16 volumes: grafana_data: {} influxdb_data: {} chronograf_data: {} 1- La primera linea del archivo acusa una instruccion \"version:\" . Indica la version base de compose que se esta utilizando para construir cada contenedor. \u00bfQue cambia elegir una version u otra? La variedad y forma de ejecutar los comandos para construir los contenedores. Enlace de referencia: https://docs.docker.com/compose/compose-file/compose-versioning/ 2- \"services:\" es la segunda linea dentro del archivo y es tan importante como la primera. Especifica los servicios que estaran presentes en cada contenedor. Como se puede observar en la porcion de codigo expuesta anteriormente, ellos se denominan como: web,locust,influxdb,grafana,etc. Cada uno de ellos, tiene configurado varios parametros. Entre ellos se encuentran: 2.1- build : especifica la ubicaci\u00f3n de nuestro Dockerfile. Un Dockerfile es un archivo de texto plano que contiene una serie de instrucciones necesarias para crear una imagen que, posteriormente, se convertir\u00e1 en una sola aplicaci\u00f3n utilizada para un determinado prop\u00f3sito. Teniendo presente que en el trabajo se estan realizando pruebas con 2 bases datos diferentes, en el segundo caso se implementa PostgreSQL, en donde se configuran 2 servicios adicionales que corresponden a la propia base de datos y a Telegraf. Siendo su docker compose correspondiente, el siguiente: version: '3.2' services: web: build: appTrafico command: python manage.py runserver 172.20.0.2:8010 volumes: - ./appTrafico:/TraficoGyL ports: - \"8010:8010\" depends_on: - db networks: red_servicios: ipv4_address: 172.20.0.2 container_name: Django db: image: postgres:13.0 environment: - POSTGRES_DB=postgres - POSTGRES_USER=postgres - POSTGRES_PASSWORD=postgres volumes: - postgres_data:/var/lib/postgresql/data - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf command: postgres -c config_file=/etc/postgresql/postgresql.conf networks: red_servicios: ipv4_address: 172.20.0.8 container_name: Postgres locust: build: ScriptLocust command: -f /mnt/locust/Test_locust_regUser_08-11-2020.py volumes: - ./ScriptLocust:/mnt/locust ports: - \"8089:8089\" links: - web:web networks: red_servicios: ipv4_address: 172.20.0.3 container_name: Locust influxdb: build: influxdb env_file: configuration.env ports: - '8086:8086' volumes: - influxdb_data:/var/lib/influxdb networks: red_servicios: ipv4_address: 172.20.0.4 container_name: Influxdb chronograf: image: chronograf:1.5 volumes: - chronograf_data:/var/lib/chronograf ports: - '8087:8888' networks: red_servicios: ipv4_address: 172.20.0.5 container_name: Chronograf telegraf: image: telegraf:1.16 volumes: - ./telegraf/telegraf.conf:/etc/telegraf/telegraf.conf:ro - /var/run/docker.sock:/var/run/docker.sock links: - influxdb networks: red_servicios: ipv4_address: 172.20.0.9 container_name: Telegraf grafana: build: grafana env_file: configuration.env links: - influxdb ports: - '3000:3000' volumes: - grafana_data:/var/lib/grafana - ./grafana/dashboard:/var/lib/grafana/dashboards networks: red_servicios: ipv4_address: 172.20.0.6 container_name: Grafana reporter: image: izakmarais/grafana-reporter:${gr_version:-latest} command: \"-ip 172.20.0.6:3000\" ports: - \"8686:8686\" networks: red_servicios: ipv4_address: 172.20.0.10 container_name: Reporter_Grafana cadvisor: image: google/cadvisor command: -storage_driver=influxdb -storage_driver_db=influx -storage_driver_host=172.20.0.4:8086 ports: - \"8080:8080\" volumes: - /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro links: - influxdb:influxdb privileged: true networks: red_servicios: ipv4_address: 172.20.0.7 container_name: cAdvisor networks: red_servicios: driver: bridge ipam: config: - subnet: 172.20.0.0/16 volumes: grafana_data: {} influxdb_data: {} chronograf_data: {} postgres_data: {} Para los servicios web, el archivo dockerfile contiene las siguientes instrucciones: FROM indica que debe utilizarse una imagen existente como base que se encuentra alojada en el sitio web \"docker hub\" ENV PYTHONUNBUFFERED 1 indica que debe imprimirse por pantalla los detalles de la ejecucion del dockerfile. Esto permite llevar un control y saber en que parte del codigo se producen errores. RUN es una instruccion que permite ejecutar comandos dentro del contenedor. En este caso, dentro de la imagen base referenciada por FROM, se creara una carpeta denominada \"TraficoGyL\" WORKDIR El comando se usa para definir el directorio de trabajo de un contenedor Docker en un momento dado. Si no se especifica, docker crea automaticamente un entorno diferente. Para que dicho entorno coincida con la carpeta que creamos, debemos utilizar el comando WORKDIR. COPY Este comando permite copiar archivos presentes en el mismo entorno donde esta alojado el dockerfile para que se hagan presentes dentro del contenedor. Esto nos resulta util, ya que definimos todos los paquetes python necesarios para el contenedor junto con sus versiones dentro del archivo requerimientos.txt y lo copiamos a la carpeta TraficoGyL dentro del contenedor. RUN Ejecutamos un comando para instalar todos los paquetes necesarios dentro del contenedor y preparar la imagen para levantar el servicio. COPY Este ultimo comando copia toda la aplicacion relacionada al servicio a la carpeta de trabajo. FROM python:3.7.9-buster ENV PYTHONUNBUFFERED 1 RUN mkdir /TraficoGyL WORKDIR /TraficoGyL COPY requerimientos.txt /TraficoGyL RUN pip3 install -r requerimientos.txt COPY . /TraficoGyL Una vez preparado el dockerfile, desde el archivo \".yml\" solamente debe indicarse la ruta donde esta presente. En nuestro caso, todo lo relacionado al servicio web, tanto la aplicacion en si, como el archivo dockerfile y requerimientos.txt se encuentran en la carpeta \"appTrafico\". Por eso la linea build: \"appTrafico\". 2.2- command : indica que en la construccion del servicio debe ejecutarse un comando particular dentro del contenedor. Para el caso de la aplicacion web, como se esta utilizando django, debe ejecutarse un comando como: python manage.py runserver (direccionIP:puerto). Esto permite que al finalizar docker-compose este presente y listo el servicio web. 2.3- volumes : Establece que un directorio del sistema operativo estara presente de una direccion particular dentro del contenedor. Esto permite importar toda la aplicacion web dentro del contenedor, y al realizar cambios en el directorio, esos cambios instantaneamente estaran presentes dentro del contenedor. Esto facilita realizar operaciones y cambios en el contenedor, sin tener que ingresar constantemente o trabajar dentro del mismo. 2.4- ports : Establece que se van a exponer los puertos del contenedor a determinados puertos del host. esto permite que los servicios y contenedores sean accesibles ademas desde fuera de la estructura dockerizada. 2.5- network : Establece que se utilizara una estructura de red interna asociada al grupo de contenedores donde cada uno tendra una direccion ip diferente. Algunos contenedores tienen ademas otros comandos como links que permiten vincular de forma explicita los diferentes servicios. Si bien ya estan dentro de la misma red y no deberia haber ningun tipo de inconveniente, se agrega dicha instruccion para apuntar un servicio a otro, esto genera que ante cualquier cambio de un contenedor, la configuracion se mantenga funcional. Los contenedores influxdb y grafana, fueron agregados teniendo en cuenta un repositorio de github, cuya referencia se encuentra a continuacion: https://github.com/BushnevYuri/DockerGrafanaInfluxKit Este proyecto funcional, incluye ademas, configuraciones adicionales que son dignas de analizar. Entre ellas env_file . Este argumento dentro de docker-compose permite especificar un archivo donde se encuentran variables de entorno que permiten configurar de forma dinamica el servicio dentro del contenedor. ################### # Grafana options ################### GF_SECURITY_ADMIN_USER=admin GF_SECURITY_ADMIN_PASSWORD=admin GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-worldmap-panel,grafana-piechart-panel #################### # InfluxDB options #################### INFLUX_USER=admin INFLUX_PASSWORD=admin INFLUX_DB=influx \u00bfSe necesita algun procedimiento adicional? La primera vez que se va a ejecutar el proyecto debe realizar migraciones de la aplicacion en django. Para ello, debe identificar el \"id\" del contenedor con el nombre \"django\". Entonces luego de inicializar toda la estructura con docker-compose up, en otra terminal ejecute los siguientes comandos como super usuario: docker ps docker exec -i -t <id_conteiner_django> /bin/bash python manage.py migrate Estos comandos ejecutados unicamente la primera vez, dejarian lista toda la estructura docker para ejecutar cualquier tipo de prueba. Si adicionalmente, desea realizar las mismas pruebas de performance que se detallan en este informe, debera realizar un paso adicional. Registrar los usuarios simulados que cargaran datos sobre la base de datos. Para ello, con toda la estructura activa debera ejecutar el archivo python denominado como \"Cargar_Usuarios_Django.py\". Este ejecutable python generara el registro de una cantidad determinada de usuarios (Variable definida dentro del Script) de forma automatica y entrega finalmente un archivo de extension \".txt\" que contendra los usuarios y contrase\u00f1as generados y cargados que leera locust para ejecutar cada prueba. Los comandos que debera llevar a cabo son: python Cargar_Usuarios_Django.py docker-compose down docker-compose up El reinicio de la estructura es necesario para que el archivo de texto se mapee dentro del contenedor locust y pueda ser accedido por el propio servicio. Sin mas detalles, quedara todo el entorno listo, para ejecutar pruebas de performance. Detalle importante: Si ya realizo todos estos pasos en su equipo donde va a desarrollar las pruebas de performance, no debe realizarlo nuevamente a menos que elimine todos los volumenes e imagenes asociadas al proyecto. Importante Aclaracion Los comandos detallados anteriormente, sirve para la estructura con PostgreSQL , ya que para la estructura de servicios con SQLite3 la base de datos viene integrada y conectada con la aplicacion, asi como con todos los datos con los que se estuvo probando. Para SQLite lo unico que necesita hacer es docker-compose up. En caso de querer limpiar la base de datos pero conservar los modelos, debera seguir los siguientes pasos: docker ps docker exec -i -t <id_conteiner_django> /bin/bash python manage.py flush En caso de querer eliminar la base de datos con sus modelos y armar una aplicacion distinta, primero debera eliminar el archivo de base de datos SQLite3 y posteriormente ejecutar: docker ps docker exec -i -t <id_conteiner_django> /bin/bash python manage.py migrate","title":"Informaci\u00f3n"},{"location":"informacion/#informacion","text":"","title":"Informaci\u00f3n"},{"location":"informacion/#como-ejecutar-el-proyecto","text":"Al descargar la carpeta correspondiente al proyecto, presente en el repositorio \"Versiones Finales\", debemos abrir una consola de comandos en la raiz del mismo, precisamente donde se encuentra el archivo docker-compose.yml y ejecutar: docker-compose up Este simple comando llevara a cabo una serie de instrucciones predefinidas que levantaran automaticamente entre 7 a 9 servicios, dependiendo de la base de datos que se este utilizando. Estos servicios son: Django en la siguiente ubicacion: 172.2x.0.2:8010 Locust en la siguiente ubicacion: 172.2x.0.3:8089 Influxdb en la siguiente ubicacion: 172.2x.0.4:8086 Chronograf en la siguiente ubicacion: 172.2x.0.5:8888 Grafana en la siguiente ubicacion: 172.2x.0.6:3000 cAdvisor en la siguiente ubicacion: 172.2x.0.7:8080 PostgreSQL (opcional) en el caso de estar usando esta db: 172.20.0.8 Telegraf (opcional) en la siguiente ubicacion: 172.20.0.9 Reporter en la siguiente ubicacion: 172.2x.0.10:8686 Como puede observarse, todos los contenedores pertenecen a la misma red interna \"172.2x.0.0/16\" (en donde la 'x' sera 0 si se usa PostgreSQL o 1 si se usa Sqlite3) y son capaces de comunicarse bajo cualquier arquitectura de red sobre la cual se levante. Con respecto al ultimo servicio, \"Reporter\", tiene unicamente la tarea de importar las metricas de Grafana a PDF. Para comprender mas en detalle como es que interactuan entre si los distintos servicios se debe de observar la siguiente figura: Esta portabilidad de la estructura entera es gracias a los beneficios que aporta Docker Compose a la tecnologia Docker, ya que Docker Compose es una herramienta que permite simplificar el uso de Docker. A partir de archivos YAML es mas sencillo crear contendores, conectarlos, habilitar puertos, volumenes, etc. Con Compose se puede crear diferentes contenedores y al mismo tiempo, en cada contenedor, diferentes servicios, unirlos a un vol\u00famen com\u00fan, iniciarlos y apagarlos, etc. Es un componente fundamental para poder construir aplicaciones y microservicios. En vez de utilizar Docker via una serie inmemorizable de comandos bash y scripts, Docker Compose permite mediante archivos YAML, poder instruir al Docker Engine a realizar tareas, preprogramadas. Y esta es la clave, la facilidad para dar una serie de instrucciones, y luego repetirlas en diferentes ambientes. A continuacion se hara una descripcion del archivo para la implementacion con SQlite: version: '3.2' services: web: build: appTrafico command: python manage.py runserver 172.21.0.2:8010 volumes: - ./appTrafico:/TraficoGyL ports: - \"8010:8010\" networks: red_servicios: ipv4_address: 172.21.0.2 container_name: Django_SQlite locust: build: ScriptLocust command: -f /mnt/locust/Test_locust_regUser_08-11-2020.py volumes: - ./ScriptLocust:/mnt/locust ports: - \"8089:8089\" links: - web:web networks: red_servicios: ipv4_address: 172.21.0.3 container_name: Locust_SQlite influxdb: build: influxdb env_file: configuration.env ports: - '8086:8086' volumes: - influxdb_data:/var/lib/influxdb networks: red_servicios: ipv4_address: 172.21.0.4 container_name: Influxdb_SQlite chronograf: image: chronograf:1.5 volumes: - chronograf_data:/var/lib/chronograf ports: - '8087:8888' networks: red_servicios: ipv4_address: 172.21.0.5 container_name: Chronograf_SQlite grafana: build: grafana env_file: configuration.env links: - influxdb ports: - '3000:3000' volumes: - grafana_data:/var/lib/grafana - ./grafana/dashboard:/var/lib/grafana/dashboards networks: red_servicios: ipv4_address: 172.21.0.6 container_name: Grafana_SQlite reporter: image: izakmarais/grafana-reporter:${gr_version:-latest} command: \"-ip 172.21.0.6:3000\" ports: - \"8686:8686\" networks: red_servicios: ipv4_address: 172.21.0.10 container_name: Reporter_Grafana_SQlite cadvisor: image: google/cadvisor command: -storage_driver=influxdb -storage_driver_db=influx -storage_driver_host=172.21.0.4:8086 ports: - \"8080:8080\" volumes: - /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro links: - influxdb:influxdb privileged: true networks: red_servicios: ipv4_address: 172.21.0.7 container_name: cAdvisor_SQlite networks: red_servicios: driver: bridge ipam: config: - subnet: 172.21.0.0/16 volumes: grafana_data: {} influxdb_data: {} chronograf_data: {} 1- La primera linea del archivo acusa una instruccion \"version:\" . Indica la version base de compose que se esta utilizando para construir cada contenedor. \u00bfQue cambia elegir una version u otra? La variedad y forma de ejecutar los comandos para construir los contenedores. Enlace de referencia: https://docs.docker.com/compose/compose-file/compose-versioning/ 2- \"services:\" es la segunda linea dentro del archivo y es tan importante como la primera. Especifica los servicios que estaran presentes en cada contenedor. Como se puede observar en la porcion de codigo expuesta anteriormente, ellos se denominan como: web,locust,influxdb,grafana,etc. Cada uno de ellos, tiene configurado varios parametros. Entre ellos se encuentran: 2.1- build : especifica la ubicaci\u00f3n de nuestro Dockerfile. Un Dockerfile es un archivo de texto plano que contiene una serie de instrucciones necesarias para crear una imagen que, posteriormente, se convertir\u00e1 en una sola aplicaci\u00f3n utilizada para un determinado prop\u00f3sito. Teniendo presente que en el trabajo se estan realizando pruebas con 2 bases datos diferentes, en el segundo caso se implementa PostgreSQL, en donde se configuran 2 servicios adicionales que corresponden a la propia base de datos y a Telegraf. Siendo su docker compose correspondiente, el siguiente: version: '3.2' services: web: build: appTrafico command: python manage.py runserver 172.20.0.2:8010 volumes: - ./appTrafico:/TraficoGyL ports: - \"8010:8010\" depends_on: - db networks: red_servicios: ipv4_address: 172.20.0.2 container_name: Django db: image: postgres:13.0 environment: - POSTGRES_DB=postgres - POSTGRES_USER=postgres - POSTGRES_PASSWORD=postgres volumes: - postgres_data:/var/lib/postgresql/data - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf command: postgres -c config_file=/etc/postgresql/postgresql.conf networks: red_servicios: ipv4_address: 172.20.0.8 container_name: Postgres locust: build: ScriptLocust command: -f /mnt/locust/Test_locust_regUser_08-11-2020.py volumes: - ./ScriptLocust:/mnt/locust ports: - \"8089:8089\" links: - web:web networks: red_servicios: ipv4_address: 172.20.0.3 container_name: Locust influxdb: build: influxdb env_file: configuration.env ports: - '8086:8086' volumes: - influxdb_data:/var/lib/influxdb networks: red_servicios: ipv4_address: 172.20.0.4 container_name: Influxdb chronograf: image: chronograf:1.5 volumes: - chronograf_data:/var/lib/chronograf ports: - '8087:8888' networks: red_servicios: ipv4_address: 172.20.0.5 container_name: Chronograf telegraf: image: telegraf:1.16 volumes: - ./telegraf/telegraf.conf:/etc/telegraf/telegraf.conf:ro - /var/run/docker.sock:/var/run/docker.sock links: - influxdb networks: red_servicios: ipv4_address: 172.20.0.9 container_name: Telegraf grafana: build: grafana env_file: configuration.env links: - influxdb ports: - '3000:3000' volumes: - grafana_data:/var/lib/grafana - ./grafana/dashboard:/var/lib/grafana/dashboards networks: red_servicios: ipv4_address: 172.20.0.6 container_name: Grafana reporter: image: izakmarais/grafana-reporter:${gr_version:-latest} command: \"-ip 172.20.0.6:3000\" ports: - \"8686:8686\" networks: red_servicios: ipv4_address: 172.20.0.10 container_name: Reporter_Grafana cadvisor: image: google/cadvisor command: -storage_driver=influxdb -storage_driver_db=influx -storage_driver_host=172.20.0.4:8086 ports: - \"8080:8080\" volumes: - /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro links: - influxdb:influxdb privileged: true networks: red_servicios: ipv4_address: 172.20.0.7 container_name: cAdvisor networks: red_servicios: driver: bridge ipam: config: - subnet: 172.20.0.0/16 volumes: grafana_data: {} influxdb_data: {} chronograf_data: {} postgres_data: {} Para los servicios web, el archivo dockerfile contiene las siguientes instrucciones: FROM indica que debe utilizarse una imagen existente como base que se encuentra alojada en el sitio web \"docker hub\" ENV PYTHONUNBUFFERED 1 indica que debe imprimirse por pantalla los detalles de la ejecucion del dockerfile. Esto permite llevar un control y saber en que parte del codigo se producen errores. RUN es una instruccion que permite ejecutar comandos dentro del contenedor. En este caso, dentro de la imagen base referenciada por FROM, se creara una carpeta denominada \"TraficoGyL\" WORKDIR El comando se usa para definir el directorio de trabajo de un contenedor Docker en un momento dado. Si no se especifica, docker crea automaticamente un entorno diferente. Para que dicho entorno coincida con la carpeta que creamos, debemos utilizar el comando WORKDIR. COPY Este comando permite copiar archivos presentes en el mismo entorno donde esta alojado el dockerfile para que se hagan presentes dentro del contenedor. Esto nos resulta util, ya que definimos todos los paquetes python necesarios para el contenedor junto con sus versiones dentro del archivo requerimientos.txt y lo copiamos a la carpeta TraficoGyL dentro del contenedor. RUN Ejecutamos un comando para instalar todos los paquetes necesarios dentro del contenedor y preparar la imagen para levantar el servicio. COPY Este ultimo comando copia toda la aplicacion relacionada al servicio a la carpeta de trabajo. FROM python:3.7.9-buster ENV PYTHONUNBUFFERED 1 RUN mkdir /TraficoGyL WORKDIR /TraficoGyL COPY requerimientos.txt /TraficoGyL RUN pip3 install -r requerimientos.txt COPY . /TraficoGyL Una vez preparado el dockerfile, desde el archivo \".yml\" solamente debe indicarse la ruta donde esta presente. En nuestro caso, todo lo relacionado al servicio web, tanto la aplicacion en si, como el archivo dockerfile y requerimientos.txt se encuentran en la carpeta \"appTrafico\". Por eso la linea build: \"appTrafico\". 2.2- command : indica que en la construccion del servicio debe ejecutarse un comando particular dentro del contenedor. Para el caso de la aplicacion web, como se esta utilizando django, debe ejecutarse un comando como: python manage.py runserver (direccionIP:puerto). Esto permite que al finalizar docker-compose este presente y listo el servicio web. 2.3- volumes : Establece que un directorio del sistema operativo estara presente de una direccion particular dentro del contenedor. Esto permite importar toda la aplicacion web dentro del contenedor, y al realizar cambios en el directorio, esos cambios instantaneamente estaran presentes dentro del contenedor. Esto facilita realizar operaciones y cambios en el contenedor, sin tener que ingresar constantemente o trabajar dentro del mismo. 2.4- ports : Establece que se van a exponer los puertos del contenedor a determinados puertos del host. esto permite que los servicios y contenedores sean accesibles ademas desde fuera de la estructura dockerizada. 2.5- network : Establece que se utilizara una estructura de red interna asociada al grupo de contenedores donde cada uno tendra una direccion ip diferente. Algunos contenedores tienen ademas otros comandos como links que permiten vincular de forma explicita los diferentes servicios. Si bien ya estan dentro de la misma red y no deberia haber ningun tipo de inconveniente, se agrega dicha instruccion para apuntar un servicio a otro, esto genera que ante cualquier cambio de un contenedor, la configuracion se mantenga funcional. Los contenedores influxdb y grafana, fueron agregados teniendo en cuenta un repositorio de github, cuya referencia se encuentra a continuacion: https://github.com/BushnevYuri/DockerGrafanaInfluxKit Este proyecto funcional, incluye ademas, configuraciones adicionales que son dignas de analizar. Entre ellas env_file . Este argumento dentro de docker-compose permite especificar un archivo donde se encuentran variables de entorno que permiten configurar de forma dinamica el servicio dentro del contenedor. ################### # Grafana options ################### GF_SECURITY_ADMIN_USER=admin GF_SECURITY_ADMIN_PASSWORD=admin GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-worldmap-panel,grafana-piechart-panel #################### # InfluxDB options #################### INFLUX_USER=admin INFLUX_PASSWORD=admin INFLUX_DB=influx","title":"\u00bfComo ejecutar el proyecto?"},{"location":"informacion/#se-necesita-algun-procedimiento-adicional","text":"La primera vez que se va a ejecutar el proyecto debe realizar migraciones de la aplicacion en django. Para ello, debe identificar el \"id\" del contenedor con el nombre \"django\". Entonces luego de inicializar toda la estructura con docker-compose up, en otra terminal ejecute los siguientes comandos como super usuario: docker ps docker exec -i -t <id_conteiner_django> /bin/bash python manage.py migrate Estos comandos ejecutados unicamente la primera vez, dejarian lista toda la estructura docker para ejecutar cualquier tipo de prueba. Si adicionalmente, desea realizar las mismas pruebas de performance que se detallan en este informe, debera realizar un paso adicional. Registrar los usuarios simulados que cargaran datos sobre la base de datos. Para ello, con toda la estructura activa debera ejecutar el archivo python denominado como \"Cargar_Usuarios_Django.py\". Este ejecutable python generara el registro de una cantidad determinada de usuarios (Variable definida dentro del Script) de forma automatica y entrega finalmente un archivo de extension \".txt\" que contendra los usuarios y contrase\u00f1as generados y cargados que leera locust para ejecutar cada prueba. Los comandos que debera llevar a cabo son: python Cargar_Usuarios_Django.py docker-compose down docker-compose up El reinicio de la estructura es necesario para que el archivo de texto se mapee dentro del contenedor locust y pueda ser accedido por el propio servicio. Sin mas detalles, quedara todo el entorno listo, para ejecutar pruebas de performance. Detalle importante: Si ya realizo todos estos pasos en su equipo donde va a desarrollar las pruebas de performance, no debe realizarlo nuevamente a menos que elimine todos los volumenes e imagenes asociadas al proyecto.","title":"\u00bfSe necesita algun procedimiento adicional?"},{"location":"informacion/#importante-aclaracion","text":"Los comandos detallados anteriormente, sirve para la estructura con PostgreSQL , ya que para la estructura de servicios con SQLite3 la base de datos viene integrada y conectada con la aplicacion, asi como con todos los datos con los que se estuvo probando. Para SQLite lo unico que necesita hacer es docker-compose up. En caso de querer limpiar la base de datos pero conservar los modelos, debera seguir los siguientes pasos: docker ps docker exec -i -t <id_conteiner_django> /bin/bash python manage.py flush En caso de querer eliminar la base de datos con sus modelos y armar una aplicacion distinta, primero debera eliminar el archivo de base de datos SQLite3 y posteriormente ejecutar: docker ps docker exec -i -t <id_conteiner_django> /bin/bash python manage.py migrate","title":"Importante Aclaracion"},{"location":"servicios/","text":"Servicios En esta instancia es conveniente destacar que para el desarrollo de una aplicaci\u00f3n web existen muchas opciones. Dentro de ellas, es posible visualizar que existen un gran n\u00famero de framework y CMS(Sistemas de Gesti\u00f3n de Contenidos o Content Management Systems por sus siglas en ingl\u00e9s). \u00bfQu\u00e9 es un framework? Un framework es un marco de trabajo. En programaci\u00f3n hace referencia a una serie de herramientas con las que puedes construir algo m\u00e1s f\u00e1cil y r\u00e1pido con alg\u00fan lenguaje de programaci\u00f3n. En el caso de desarrollo web, se denominan frameworks de aplicaciones web. Este tipo de marco de trabajo es un tipo de framework que permite el desarrollo de sitios web din\u00e1micos, web services (servicios web) y aplicaciones web. El prop\u00f3sito de este tipo de framework es permitir a los desarrolladores construir aplicaciones web y centrarse en los aspectos interesantes, aliviando la t\u00edpica tarea repetitiva asociada con patrones comunes de desarrollo web. La mayor\u00eda de los frameworks de aplicaciones web proporcionan los tipos de funcionalidad b\u00e1sica com\u00fan, tales como sistemas de templates (plantillas), manejo de sesiones de usuario, interfaces comunes con el disco o el almacenamiento en base de datos de contenido cacheado, y persistencia de datos. Normalmente, los frameworks de aplicaci\u00f3n web adem\u00e1s promueven la reutilizaci\u00f3n y conectividad de los componentes, as\u00ed como la reutilizaci\u00f3n de c\u00f3digo, y la implementaci\u00f3n de bibliotecas para el acceso a base de datos. Si existe un gran n\u00famero de framework, \u00bfQu\u00e9 criterio seria necesario para elegir uno? En desarrollos de gran magnitud, un framework de calidad proporciona una estructura simple y sencilla para organizar el proyecto. Adem\u00e1s de otorgarle al desarrollador la suficiente libertad como para crear contenido \u00fanico asociado al sitio web sin interferir. Esto significa que bajo la utilizaci\u00f3n de un gran framework ser\u00e1 posible encontrar un mont\u00f3n de proyectos distintos y muy variados uno a otro. \u00faltimamente, los framework m\u00e1s populares y vers\u00e1tiles manejan una estructura Modelo-Vista-Controlador(MVC). En este patr\u00f3n, el \"Modelo\" hace referencia al acceso a la capa de datos, la \"Vista\" se refiere a la parte del sistema que selecciona qu\u00e9 mostrar y c\u00f3mo mostrarlo, y el \"Controlador\" implica la parte del sistema que decide qu\u00e9 vista usar, dependiendo de la entrada del usuario, accediendo al modelo si es necesario. Frameworks m\u00e1s populares Hay una amplia gama de frameworks para aplicaciones web disponibles para Linux que son distribuidos bajo licencia Open Source. Entre ellos puede destacarse: Angular.js Un framework basado en JavaScript Ruby on Rails Framework MVC basado en Ruby, orientado al desarrollo de aplicaciones web CodeIgniter Poderoso framework PHP liviano y r\u00e1pido Django Framework Python que promueve el desarrollo r\u00e1pido y el dise\u00f1o limpio Pylons Framework web para Python que enfatiza la flexibilidad y el desarrollo r\u00e1pido CakePHP Basado en PHP Zend Framework Basado en PHP Yii Basado en PHP En realidad,\u00bfHace falta un framework? Una respuesta sencilla ser\u00eda s\u00ed, ya que este nos ahorra much\u00edsimo trabajo y nos ayuda a optimizar nuestro tiempo efectivo, adem\u00e1s que nos facilita las cosas al momento de escribir c\u00f3digo. Adem\u00e1s, si utilizamos un framework basado en un lenguaje de programaci\u00f3n como Python encontraremos que podremos desarrollar aplicaciones elaboradas con pocos conocimientos de programaci\u00f3n. Ya que es un lenguaje de programaci\u00f3n sencillo, de alto nivel, f\u00e1cil de entender en cuanto a c\u00f3digo y adem\u00e1s con muchas librer\u00edas y una comunidad muy grande. Por eso es muy importante analizar frameworks como Django. \u00bfPor qu\u00e9 usar Django? Django est\u00e1 centrado en el desarrollo r\u00e1pido de aplicaciones web y sobre todo usando el principio de la programaci\u00f3n DRY (No te repitas) y es algo importante en el core de este framework. Django se puede ejecutar en cualquier sistema operativo. S\u00f3lo es necesario instalar Python (Mac y Linux tienen python por defecto) y gracias al gestor de paquetes de python (PIP) instalarlo es tan sencillo como ejecutar este comando pip install django \u00bfQu\u00e9 hace genial a Django? Administrador : Django cuenta con un administrador que viene activo por defecto donde se pueden con un par de l\u00edneas de c\u00f3digo mostrar los modelos de las bases de datos y poder crear, editar, ver y eliminar registros. Formularios : Crear formularios en Django es muy sencillo y se pueden crear de dos formas, un formulario definiendo uno a uno los campos o usar un modelo de la base de datos y Django crea el formulario por nosotros. Rutas : El manejo de rutas hace que crear urls complejas sea sencillo de implementar, Django usa el poder de las expresiones regulares de python para hacer este trabajo. Autenticaci\u00f3n : Django provee un sistema de autenticaci\u00f3n que permite que no nos preocupemos por crear un flujo de login y registro. Permisos : En Django se tiene control de los permisos a tal punto de decir que usuario puede o no crear, editar, ver y eliminar registros de un modelo especifico. Bases de Datos : Como lo mencion\u00e9 Django cuenta con un ORM que nos permite preocuparnos en la l\u00f3gica de nuestra aplicaci\u00f3n dejando al ORM la responsabilidad de la comunicaci\u00f3n con la base de datos, es compatible con los principales motores de bases de datos como PostgreSQL, MySQL, Oracle, SQLServer entre otros. Extensible : Django puede ser extendido f\u00e1cilmente instalando paquetes adicionales para crear aplicaciones una tienda, un blog o un API Restful, se encuentran agrupados y ordenados en Django Packages. Comunidad : Django tiene una gran comunidad que encuentras siempre en los foros de ayuda y listas de correos. Documentaci\u00f3n : Django tiene una documentaci\u00f3n muy completa que te ense\u00f1a con ejemplos de c\u00f3digo como implementar o usar cada una de sus caracter\u00edsticas. \u00bfC\u00f3mo funciona? Internamente, Django sigue el patr\u00f3n MVC tan al pie de la letra que puede ser llamado un framework MVC. Donde, la M, V y C se separan en Django de la siguiente manera: M , la porci\u00f3n de acceso a la base de datos, es manejada por la capa de la base de datos de Django. V , la porci\u00f3n que selecciona qu\u00e9 datos mostrar y c\u00f3mo mostrarlos, es manejada por la vista y las plantillas. C , la porci\u00f3n que delega a la vista dependiendo de la entrada del usuario, es manejada por el framework mismo siguiendo la URLconf y llamando a la funci\u00f3n apropiada de Python para la URL obtenida. Debido a que la \"C\" es manejada por el mismo framework y la parte m\u00e1s importante se produce en los modelos, las plantillas y las vistas, Django es conocido como un Framework MTV. En el patr\u00f3n de dise\u00f1o MTV: M significa \"Model\" (Modelo), la capa de acceso a la base de datos. Esta capa contiene toda la informaci\u00f3n sobre los datos: c\u00f3mo acceder a estos, c\u00f3mo validarlos, cu\u00e1l es el comportamiento que tiene, y las relaciones entre los datos. T significa \"Template\" (Plantilla), la capa de presentaci\u00f3n. Esta capa contiene las decisiones relacionadas a la presentaci\u00f3n: como algunas cosas son mostradas sobre una p\u00e1gina web o otro tipo de documento. V significa \"View\" (Vista), la capa de la l\u00f3gica de negocios. Esta capa contiene la l\u00f3gica que accede al modelo y la delega a la plantilla apropiada: Se puede pensar en esto como un puente entre los modelos y las plantillas. Con esta estructura, Django se rige bajo el siguiente proceso: El usuario hace una petici\u00f3n, a trav\u00e9s de una direcci\u00f3n web (URL). Django realiza una consulta para saber qu\u00e9 hacer con la petici\u00f3n. Una vez que sabe qu\u00e9 tarea realizar le env\u00eda la petici\u00f3n a la vista que corresponde. La vista realiza las acciones necesarias en la base de datos. Si lo necesita tambi\u00e9n utiliza la definici\u00f3n de los formularios. Para despu\u00e9s responder a la petici\u00f3n mostrando la p\u00e1gina que contiene esa URL. \u00bfQu\u00e9 es un CMS? Un CMS o Sistema de Gesti\u00f3n de Contenidos es un programa que le permite al usuario un f\u00e1cil manejo de informaci\u00f3n para su p\u00e1gina de Internet. Es decir, es una herramienta que le da la facultad al usuario para crear, editar, publicar e incluso clasificar contenidos en su sitio web sin tener que estar lidiando con lenguajes complejos de programaci\u00f3n. El CMS gratuito suele ser desarrollado por una comunidad de programadores que voluntariamente mejoran y lanzan nuevas ediciones del software, por lo que el soporte t\u00e9cnico directo es dif\u00edcil de encontrar. Para solucionar cualquier problema es m\u00e1s f\u00e1cil buscar respuestas en foros de usuarios. Los tres proyectos de c\u00f3digo abierto y con licencia gratuita m\u00e1s conocidos son WordPress, Joomla y Drupal. La utilizaci\u00f3n de un CMS facilita la vida de muchos usuarios sin conocimientos t\u00e9cnicos para administrar contenidos, pero tambi\u00e9n puede suponer inconvenientes que es necesario conocer en profundidad antes de decidirte por uno de ellos. A continuaci\u00f3n, se expone un listado con las principales ventajas y desventajas a la hora de recurrir a un gestor de contenido \u00bfCu\u00e1les son las ventajas de usar un CMS? El desarrollo de tu sitio web ser\u00e1 m\u00e1s r\u00e1pido. No es lo mismo tener que implementar funcionalidades a mano que las tareas las realice autom\u00e1ticamente un CMS. Facilidad de uso. Muchos CMS actuales son muy f\u00e1ciles de usar, por lo que no es necesario tener un amplio conocimiento en programaci\u00f3n para poder crear, modificar o actualizar el contenido. Personalizaci\u00f3n. Los CMS te permiten personalizar el dise\u00f1o web de tu p\u00e1gina, as\u00ed como individualizar las funcionalidades de la plataforma del gestor de contenidos. As\u00ed, se puede implementar r\u00e1pidamente un calendario de eventos, un formulario o una encuesta, entre otros ejemplos, tres acciones que de otra manera te costar\u00edan bastante m\u00e1s trabajo si no cuentas con habilidades t\u00e9cnicas. Escalabilidad. Es decir, puedes a\u00f1adir nuevas funcionalidades a tu sitio web en cualquier momento, ya sea a trav\u00e9s de plugins o m\u00f3dulos. Posicionamiento SEO. Puedes posicionar tu sitio web en Google si cuentas con un gestor de contenidos \u201cSEO friendly\u201d, o lo que es lo mismo, que incluya herramientas de optimizaci\u00f3n de contenidos para mejorar tu posici\u00f3n en los motores de b\u00fasqueda. Ahorro econ\u00f3mico. Es mucho m\u00e1s barato desarrollar un sitio web con un CMS que comenzar desde cero, adem\u00e1s de que te ahorras la asistencia t\u00e9cnica si aprendes por ti mismo a solucionar los peque\u00f1os problemas que te vayas encontrando. Seguridad. El servidor de un CMS cuenta con actualizaciones constantes para evitar incidencias de seguridad que afecten a sus usuarios. \u00bfCu\u00e1les son las desventajas de usar un CMS? Requiere mantenerlo siempre actualizado. De lo contrario, su sitio web puede sufrir fallas de seguridad, ideales para los hackers. Tambi\u00e9n puedes sufrir problemas de lentitud en tu sitio, de ah\u00ed la importancia de las actualizaciones. Menos elasticidad. Los CMS de c\u00f3digo abierto suponen una estructura m\u00e1s o menos r\u00edgida, donde podemos hacer lo que queramos siempre que nos atengamos a la configuraci\u00f3n propia de la plataforma. Aprendizaje. Los usuarios deben de aprender nociones m\u00ednimas para administrar su sitio web o de lo contrario requerir\u00e1n pagar personal con experiencia para que el CMS est\u00e9 perfectamente actualizado. Costes adicionales. Ya sea porque quieres mejorar el sitio comprando una plantilla muy original o porque necesitas incrementar funcionalidades que suponen un precio. \u00bfPor qu\u00e9 utilizar Django y no un CMS? En primer lugar, son dos cosas distintas. B\u00e1sicamente, WordPress es el tablero a trav\u00e9s del cual organiza el texto y las im\u00e1genes para mostrar en su sitio web. WordPress est\u00e1 construido utilizando el lenguaje de programaci\u00f3n PHP. Django, por otro lado, es lo que se llama un marco web. Basado en el potente lenguaje de programaci\u00f3n Python, es un conjunto de herramientas y bibliotecas que se pueden implementar r\u00e1pidamente para crear aplicaciones web personalizadas. \u00bfCu\u00e1ndo me servir\u00eda wordpress? Cuando desee crear un sitio web basado en una funcionalidad muy explotada y utilizada en el marco del desarrollo web, ya que es muy probable que dicha herramienta tenga incorporado temas y plugins necesarios para implementar en su sitio web. WordPress es una herramienta sencilla y econ\u00f3mica para un sitio b\u00e1sico. Con una gran cantidad de temas gratuitos para descargar, es una forma r\u00e1pida de conectarse y comenzar a promocionar su contenido / negocio / actividad secundaria. Sin embargo, para generar una p\u00e1gina con una funcionalidad original y particular, que se adapte a las necesidades de la aplicaci\u00f3n, estas herramientas (CMS) son menos flexibles, por lo que Django adquiere mucha importancia, proporcionando un marco flexible para implementar soluciones web personalizadas, escalables e innovadoras. Servicio a implementar Teniendo presentes la finalidad del trabajo y ya justificada la elecci\u00f3n por Django, es que se plantea el siguiente proyecto compuesto por 3 etapas, tal como se ve a continuaci\u00f3n: Esta aplicaci\u00f3n, como se observa en la imagen tiene la finalidad de permitir a cualquier usuario que visite la p\u00e1gina web y mediante una consulta poder visualizar informaci\u00f3n de datos meteorol\u00f3gicos que se encuentran disponibles en las bases de datos y que al mismo tiempo han sido cargados por los diversos sensores con que cuenta la red simulada. Con respecto al acceso a carga de datos al sistema, como se observa a la izquierda, cada uno de los sensores debe de pasar en primera instancia una etapa de registro y/o login para poder alojar su informaci\u00f3n en la base de datos. Composici\u00f3n del Servicio Django Para comprender como es que funciona el servicio encargado de generar la p\u00e1gina web, se debe analizar c\u00f3mo se encuentra la carpeta asociada al servicio y que lleva el nombre de \u201cappTrafico\u201d, esta carpeta se puede encontrar dentro del repositorio en la direcci\u00f3n \u201c/Versiones Finales/Proyecto_con_SQlite3/appTrafico\u201d o tambi\u00e9n dentro de \u201c/Versiones Finales/Proyecto_con_PostgreSQL/appTrafico\u201d, su composici\u00f3n es: Para realizar una descripci\u00f3n de la composici\u00f3n de los componentes fundamentales del directorio, primero se debe de observar que al estar trabajando con un esquema dockerizado, se cuenta con un archivo \u201cdockerfile\u201d, este archivo adem\u00e1s de contar con los distintos comandos para poner en funcionamiento Django, necesita de un documento el cual le indica los distintos programas que se necesitan instalar para el total funcionamiento de la aplicaci\u00f3n, en este caso el archivo en cuesti\u00f3n es \u201crequerimientos.txt\u201d. Situado arriba de este archivo, se encuentra \u201cmanage.py\u201d, este script sirve para ejecutar y administrar las herramientas de Django necesarias para este proyecto. Despu\u00e9s se cuenta con 4 carpetas, estas son: \u201dtemplates\u201d ,\u201dstatic\u201d, \u201cregistro\u201d y \u201cconfig\u201d. Templates: Es la carpeta que contiene los html b\u00e1sicos para la aplicaci\u00f3n, en donde uno de sus archivos fundamentales, es \u201cbase.html\u201d, este contiene gran mayor\u00eda de las etiquetas html y que ser\u00e1n heredadas por los distintos html que utilicemos para las ventanas de la p\u00e1gina web. Se podr\u00eda interpretar que es el encargado de dar el esqueleto, donde luego cada pesta\u00f1a sobre esta configuraci\u00f3n b\u00e1sica, agregara el aspecto que sea requerido. Static: Es el directorio encargado de contener los archivos est\u00e1ticos, como son por ejemplo las im\u00e1genes o iconos que se utilizan en la p\u00e1gina web o graficas que son generadas por el servicio y es el directorio de almacenamiento para este contenido Registro: Es el nombre que se le designo a la aplicaci\u00f3n de Django. Que dentro contiene todos los archivos \u201c.py\u201d y \u201c.html\u201d asociados al comportamiento y para la visualizaci\u00f3n de la aplicaci\u00f3n. Su contenido es el siguiente: Dentro de la carpeta \u201ctemplates\u201d es que se encuentran todos los archivos \u201c.html\u201d, luego est\u00e1n todos los scripts necesarios para el funcionamiento de la api. \u201cadmin.py\u201d contiene los modelos que se definir\u00e1n en el proyecto, para este caso se han definido dos, los cuales son \u201csensor\u201d y \u201csensor_dato\u201d. El primero contiene los datos del sensor registrado y \u201csensor_dato\u201d tiene los datos, asociados al clima y ubicaci\u00f3n, que han cargado cada uno de los sensores y que ser\u00e1n los datos que se entregar\u00e1n ante las distintas consultas de los usuarios que accedan a la aplicaci\u00f3n. Estos modelos se encuentran descriptos en \u201cmodels.py\u201d en donde se define los campos que solicita cada uno de ellos para realizar un correcto registro del modelo. \u201cviews.py\u201d contiene la l\u00f3gica de la navegaci\u00f3n por la aplicaci\u00f3n, asociada a las url en \u201curls.py\u201d definidas. Para esta implementaci\u00f3n se han definido 4 urls, los cuales tienen asociados distintos formularios, seg\u00fan los requerimientos y definidos en \u201cforms.py\u201d. Como as\u00ed tambi\u00e9n se direccionar\u00e1 hacia los distintos \u201c.html\u201d ubicados en \u201c/templates\u201d que tiene vinculada cada url. Config: Es la \u00faltima carpeta y contiene todas las configuraciones asociadas al sitio web. Su composici\u00f3n es: El script \u201csettings.py\u201d tiene todas las configuraciones necesarias del sitio, por lo que es donde se registra todas las aplicaciones que se crean, la localizaci\u00f3n de los ficheros est\u00e1ticos, los detalles de configuraci\u00f3n de la base de datos, etc. \u201curls.py\u201d define los mapeos url-vistas. A pesar de que \u00e9ste podr\u00eda contener todo el c\u00f3digo del mapeo url, es m\u00e1s com\u00fan repartir parte del mapeo a las propias aplicaciones, como sucedi\u00f3 en \u201c/registro\u201d. \u201cwsgi.py\u201d y \u201casgi.py\u201d se utilizan para ayudar a la aplicaci\u00f3n Django a comunicarse con el servidor web. De todos estos scripts, el m\u00e1s importante a describir es \u201csettings.py\u201d, en el cual algunas de las configuraciones m\u00e1s importantes son: BASE_DIR: Es la variable que tiene como contenido la ruta a una determinada ubicaci\u00f3n del proyecto, en este caso esta direccionado hacia la ubicaci\u00f3n del settings.py SECRET_KEY: Es la contrase\u00f1a asociada con el proyecto Django DEBUG: Es una variable booleana, que debe configurarse en True mientras el proyecto est\u00e9 en desarrollo, para poder ver los posibles errores por parte de Django. En caso de llevar el proyecto a producci\u00f3n, el estado de esta variable debe configurarse en False. ALLOWED_HOSTS: Asigna los host que pueden acceder al proyecto, esta variable debe de estar bien configurada para poder hacer acceso a la aplicaci\u00f3n desde otros host INSTALLED_APPS: Es en donde se establecen las aplicaciones propias y de terceros que se van a utilizar, como es el caso del debug implementado para Django o la recolecci\u00f3n de m\u00e9tricas hacia InfluxDB MIDDLEWARE: Es un sub framework que permite modificaciones al sistema de procesamiento de request/response de Django, en donde cada componente middleware es responsable de hacer alguna funci\u00f3n espec\u00edfica y suele estar acompa\u00f1ado con las aplicaciones que se agregan en \u201cINSTALLED_APPS\u201d TEMPLATES: Se describe al proyecto en donde debe de buscar las plantillas para implementar en la aplicaci\u00f3n DATABASES: Es la variable de configuraci\u00f3n asociada a la base de datos a implementar, en este caso en particular se podr\u00e1 ver configurado SQlite 3 o PostgreSQL seg\u00fan sea el caso. DEBUG_TOOLBAR_PANELS: Son las configuraciones para los distintos datos que nos entregara el debug a\u00f1adido como aplicaci\u00f3n en \u201cINSTALLED_APPS\u201d y que se visualizaran al navegar por la p\u00e1gina web INFLUXDB_: Son las distintas configuraciones necesarias para que las m\u00e9tricas obtenidas en Django sean llevadas hacia InfluxDB, nuevamente estas configuraciones est\u00e1n asociadas con la aplicaci\u00f3n a\u00f1adida en \u201cINSTALLED_APPS\u201d Navegaci\u00f3n por el servicio Django Para poder entender la navegaci\u00f3n dentro de la aplicaci\u00f3n, es que se presenta un diagrama de flujo el cual contiene todas las pestanas asociadas a la p\u00e1gina web y que dan sentido a la implementaci\u00f3n de todas las configuraciones antes mencionadas. Para comprender el funcionamiento de la navegaci\u00f3n es que se debe tener presente que la aplicaci\u00f3n podr\u00e1 ser consultada por 2 grupos diferenciados, siendo estos Sensores y Usuarios, los cuales experimentaran una navegaci\u00f3n diferente. Una vez mencionado este detalle, el diagrama de flujo es: Para acceder a la pagina web se debe ingresar la direcci\u00f3n: http://127.0.0.1:8010 o http://172.2x.0.2:8010 en el caso de estar accediendo desde el mismo host, en caso de acceder de manera externa, se debe de acceder mediante el ip que tiene asignado el host que contiene el servicio y redireccionar hacia el puerto 8010, tal como se hizo en las dos direcciones anteriores. Una vez que se ha accedido a la p\u00e1gina se podr\u00e1 ver un panel superior desplegable, el cual nos puede llevar a el mismo home en el cual nos encontramos, a realizar un registro de un nuevo sensor o una carga de datos por parte de los sensores. En la parte central de la p\u00e1gina est\u00e1n los botones asociados a \u201ciniciar sesi\u00f3n\u201d o \u201cconsultar datos\u201d es en esta instancia que la navegaci\u00f3n por la p\u00e1gina web bifurca seg\u00fan sea el caso de un sensor que inicie sesi\u00f3n o un usuario que consulte datos climatol\u00f3gicos. Considerando el caso de este \u00faltimo, se lo llevar\u00e1 hacia una nueva url asociada a \u201c/registro/procUser\u201d en donde el usuario mediante el correcto llenado de un formulario que solicita la ubicaci\u00f3n y caracter\u00edsticas climatol\u00f3gicas, podr\u00e1 visualizar los datos solicitados a la base de datos y, si as\u00ed lo desea, realizar nuevas consultas mediante la variaci\u00f3n en el formulario antes comentado. Con respecto a los sensores y en la otra rama de navegaci\u00f3n, estos deber\u00e1n iniciar sesi\u00f3n en donde ser\u00e1n llevados a \u201c/accounts/login\u201d, si se diera el caso de que el sensor no este registrado, debe de ingresar a \u201c/registro/nuevo\u201d para un posterior login. Una vez que el sensor ha iniciado sesi\u00f3n correctamente, es que podr\u00e1 acceder a \u201c/registro/privado\u201d para poder cargar los datos asociados a su ubicaci\u00f3n geogr\u00e1fica y los datos climatol\u00f3gicos obtenidos, estos datos ser\u00e1n cargados mediante un formulario, que en el caso de estar ingresados de manera correcta ser\u00e1n registrados en la base de datos. Luego el sensor podr\u00e1 ver sus \u00faltimos registros cargados visualiz\u00e1ndose mediante una tabla y distintas gr\u00e1ficas. Fuente de Informacion https://openwebinars.net/blog/que-es-django-y-por-que-usarlo/ https://devcode.la/blog/por-que-usar-django/ https://www.azulschool.net/que-es-django-y-para-que-sirve/ https://platzi.com/blog/django-el-framework-para-desarrollo-web/ https://codingornot.com/django-por-que-usar-django https://www.djangosites.org/ https://djangopackages.org/ https://www.opensourcecms.com/ https://www.comparahosting.com/que-es-un-cms-y-para-que-sirve/ https://elbauldelprogramador.com/los-10-mejores-frameworks-gratis-de-aplicaciones-web/ https://www.django-cms.org/en/why-django-cms/ https://uniwebsidad.com/libros/django-1-0/capitulo-5/el-patron-de-diseno-mtv https://medium.com/infeenix/django-vs-wordpress-c%C3%B3mo-me-decido-97442a76c8d2","title":"Servicios"},{"location":"servicios/#servicios","text":"En esta instancia es conveniente destacar que para el desarrollo de una aplicaci\u00f3n web existen muchas opciones. Dentro de ellas, es posible visualizar que existen un gran n\u00famero de framework y CMS(Sistemas de Gesti\u00f3n de Contenidos o Content Management Systems por sus siglas en ingl\u00e9s).","title":"Servicios"},{"location":"servicios/#que-es-un-framework","text":"Un framework es un marco de trabajo. En programaci\u00f3n hace referencia a una serie de herramientas con las que puedes construir algo m\u00e1s f\u00e1cil y r\u00e1pido con alg\u00fan lenguaje de programaci\u00f3n. En el caso de desarrollo web, se denominan frameworks de aplicaciones web. Este tipo de marco de trabajo es un tipo de framework que permite el desarrollo de sitios web din\u00e1micos, web services (servicios web) y aplicaciones web. El prop\u00f3sito de este tipo de framework es permitir a los desarrolladores construir aplicaciones web y centrarse en los aspectos interesantes, aliviando la t\u00edpica tarea repetitiva asociada con patrones comunes de desarrollo web. La mayor\u00eda de los frameworks de aplicaciones web proporcionan los tipos de funcionalidad b\u00e1sica com\u00fan, tales como sistemas de templates (plantillas), manejo de sesiones de usuario, interfaces comunes con el disco o el almacenamiento en base de datos de contenido cacheado, y persistencia de datos. Normalmente, los frameworks de aplicaci\u00f3n web adem\u00e1s promueven la reutilizaci\u00f3n y conectividad de los componentes, as\u00ed como la reutilizaci\u00f3n de c\u00f3digo, y la implementaci\u00f3n de bibliotecas para el acceso a base de datos.","title":"\u00bfQu\u00e9 es un framework?"},{"location":"servicios/#si-existe-un-gran-numero-de-framework-que-criterio-seria-necesario-para-elegir-uno","text":"En desarrollos de gran magnitud, un framework de calidad proporciona una estructura simple y sencilla para organizar el proyecto. Adem\u00e1s de otorgarle al desarrollador la suficiente libertad como para crear contenido \u00fanico asociado al sitio web sin interferir. Esto significa que bajo la utilizaci\u00f3n de un gran framework ser\u00e1 posible encontrar un mont\u00f3n de proyectos distintos y muy variados uno a otro. \u00faltimamente, los framework m\u00e1s populares y vers\u00e1tiles manejan una estructura Modelo-Vista-Controlador(MVC). En este patr\u00f3n, el \"Modelo\" hace referencia al acceso a la capa de datos, la \"Vista\" se refiere a la parte del sistema que selecciona qu\u00e9 mostrar y c\u00f3mo mostrarlo, y el \"Controlador\" implica la parte del sistema que decide qu\u00e9 vista usar, dependiendo de la entrada del usuario, accediendo al modelo si es necesario.","title":"Si existe un gran n\u00famero de framework, \u00bfQu\u00e9 criterio seria necesario para elegir uno?"},{"location":"servicios/#frameworks-mas-populares","text":"Hay una amplia gama de frameworks para aplicaciones web disponibles para Linux que son distribuidos bajo licencia Open Source. Entre ellos puede destacarse: Angular.js Un framework basado en JavaScript Ruby on Rails Framework MVC basado en Ruby, orientado al desarrollo de aplicaciones web CodeIgniter Poderoso framework PHP liviano y r\u00e1pido Django Framework Python que promueve el desarrollo r\u00e1pido y el dise\u00f1o limpio Pylons Framework web para Python que enfatiza la flexibilidad y el desarrollo r\u00e1pido CakePHP Basado en PHP Zend Framework Basado en PHP Yii Basado en PHP","title":"Frameworks m\u00e1s populares"},{"location":"servicios/#en-realidadhace-falta-un-framework","text":"Una respuesta sencilla ser\u00eda s\u00ed, ya que este nos ahorra much\u00edsimo trabajo y nos ayuda a optimizar nuestro tiempo efectivo, adem\u00e1s que nos facilita las cosas al momento de escribir c\u00f3digo. Adem\u00e1s, si utilizamos un framework basado en un lenguaje de programaci\u00f3n como Python encontraremos que podremos desarrollar aplicaciones elaboradas con pocos conocimientos de programaci\u00f3n. Ya que es un lenguaje de programaci\u00f3n sencillo, de alto nivel, f\u00e1cil de entender en cuanto a c\u00f3digo y adem\u00e1s con muchas librer\u00edas y una comunidad muy grande. Por eso es muy importante analizar frameworks como Django.","title":"En realidad,\u00bfHace falta un framework?"},{"location":"servicios/#por-que-usar-django","text":"Django est\u00e1 centrado en el desarrollo r\u00e1pido de aplicaciones web y sobre todo usando el principio de la programaci\u00f3n DRY (No te repitas) y es algo importante en el core de este framework. Django se puede ejecutar en cualquier sistema operativo. S\u00f3lo es necesario instalar Python (Mac y Linux tienen python por defecto) y gracias al gestor de paquetes de python (PIP) instalarlo es tan sencillo como ejecutar este comando pip install django","title":"\u00bfPor qu\u00e9 usar Django?"},{"location":"servicios/#que-hace-genial-a-django","text":"Administrador : Django cuenta con un administrador que viene activo por defecto donde se pueden con un par de l\u00edneas de c\u00f3digo mostrar los modelos de las bases de datos y poder crear, editar, ver y eliminar registros. Formularios : Crear formularios en Django es muy sencillo y se pueden crear de dos formas, un formulario definiendo uno a uno los campos o usar un modelo de la base de datos y Django crea el formulario por nosotros. Rutas : El manejo de rutas hace que crear urls complejas sea sencillo de implementar, Django usa el poder de las expresiones regulares de python para hacer este trabajo. Autenticaci\u00f3n : Django provee un sistema de autenticaci\u00f3n que permite que no nos preocupemos por crear un flujo de login y registro. Permisos : En Django se tiene control de los permisos a tal punto de decir que usuario puede o no crear, editar, ver y eliminar registros de un modelo especifico. Bases de Datos : Como lo mencion\u00e9 Django cuenta con un ORM que nos permite preocuparnos en la l\u00f3gica de nuestra aplicaci\u00f3n dejando al ORM la responsabilidad de la comunicaci\u00f3n con la base de datos, es compatible con los principales motores de bases de datos como PostgreSQL, MySQL, Oracle, SQLServer entre otros. Extensible : Django puede ser extendido f\u00e1cilmente instalando paquetes adicionales para crear aplicaciones una tienda, un blog o un API Restful, se encuentran agrupados y ordenados en Django Packages. Comunidad : Django tiene una gran comunidad que encuentras siempre en los foros de ayuda y listas de correos. Documentaci\u00f3n : Django tiene una documentaci\u00f3n muy completa que te ense\u00f1a con ejemplos de c\u00f3digo como implementar o usar cada una de sus caracter\u00edsticas.","title":"\u00bfQu\u00e9 hace genial a Django?"},{"location":"servicios/#como-funciona","text":"Internamente, Django sigue el patr\u00f3n MVC tan al pie de la letra que puede ser llamado un framework MVC. Donde, la M, V y C se separan en Django de la siguiente manera: M , la porci\u00f3n de acceso a la base de datos, es manejada por la capa de la base de datos de Django. V , la porci\u00f3n que selecciona qu\u00e9 datos mostrar y c\u00f3mo mostrarlos, es manejada por la vista y las plantillas. C , la porci\u00f3n que delega a la vista dependiendo de la entrada del usuario, es manejada por el framework mismo siguiendo la URLconf y llamando a la funci\u00f3n apropiada de Python para la URL obtenida. Debido a que la \"C\" es manejada por el mismo framework y la parte m\u00e1s importante se produce en los modelos, las plantillas y las vistas, Django es conocido como un Framework MTV. En el patr\u00f3n de dise\u00f1o MTV: M significa \"Model\" (Modelo), la capa de acceso a la base de datos. Esta capa contiene toda la informaci\u00f3n sobre los datos: c\u00f3mo acceder a estos, c\u00f3mo validarlos, cu\u00e1l es el comportamiento que tiene, y las relaciones entre los datos. T significa \"Template\" (Plantilla), la capa de presentaci\u00f3n. Esta capa contiene las decisiones relacionadas a la presentaci\u00f3n: como algunas cosas son mostradas sobre una p\u00e1gina web o otro tipo de documento. V significa \"View\" (Vista), la capa de la l\u00f3gica de negocios. Esta capa contiene la l\u00f3gica que accede al modelo y la delega a la plantilla apropiada: Se puede pensar en esto como un puente entre los modelos y las plantillas. Con esta estructura, Django se rige bajo el siguiente proceso: El usuario hace una petici\u00f3n, a trav\u00e9s de una direcci\u00f3n web (URL). Django realiza una consulta para saber qu\u00e9 hacer con la petici\u00f3n. Una vez que sabe qu\u00e9 tarea realizar le env\u00eda la petici\u00f3n a la vista que corresponde. La vista realiza las acciones necesarias en la base de datos. Si lo necesita tambi\u00e9n utiliza la definici\u00f3n de los formularios. Para despu\u00e9s responder a la petici\u00f3n mostrando la p\u00e1gina que contiene esa URL.","title":"\u00bfC\u00f3mo funciona?"},{"location":"servicios/#que-es-un-cms","text":"Un CMS o Sistema de Gesti\u00f3n de Contenidos es un programa que le permite al usuario un f\u00e1cil manejo de informaci\u00f3n para su p\u00e1gina de Internet. Es decir, es una herramienta que le da la facultad al usuario para crear, editar, publicar e incluso clasificar contenidos en su sitio web sin tener que estar lidiando con lenguajes complejos de programaci\u00f3n. El CMS gratuito suele ser desarrollado por una comunidad de programadores que voluntariamente mejoran y lanzan nuevas ediciones del software, por lo que el soporte t\u00e9cnico directo es dif\u00edcil de encontrar. Para solucionar cualquier problema es m\u00e1s f\u00e1cil buscar respuestas en foros de usuarios. Los tres proyectos de c\u00f3digo abierto y con licencia gratuita m\u00e1s conocidos son WordPress, Joomla y Drupal. La utilizaci\u00f3n de un CMS facilita la vida de muchos usuarios sin conocimientos t\u00e9cnicos para administrar contenidos, pero tambi\u00e9n puede suponer inconvenientes que es necesario conocer en profundidad antes de decidirte por uno de ellos. A continuaci\u00f3n, se expone un listado con las principales ventajas y desventajas a la hora de recurrir a un gestor de contenido","title":"\u00bfQu\u00e9 es un CMS?"},{"location":"servicios/#cuales-son-las-ventajas-de-usar-un-cms","text":"El desarrollo de tu sitio web ser\u00e1 m\u00e1s r\u00e1pido. No es lo mismo tener que implementar funcionalidades a mano que las tareas las realice autom\u00e1ticamente un CMS. Facilidad de uso. Muchos CMS actuales son muy f\u00e1ciles de usar, por lo que no es necesario tener un amplio conocimiento en programaci\u00f3n para poder crear, modificar o actualizar el contenido. Personalizaci\u00f3n. Los CMS te permiten personalizar el dise\u00f1o web de tu p\u00e1gina, as\u00ed como individualizar las funcionalidades de la plataforma del gestor de contenidos. As\u00ed, se puede implementar r\u00e1pidamente un calendario de eventos, un formulario o una encuesta, entre otros ejemplos, tres acciones que de otra manera te costar\u00edan bastante m\u00e1s trabajo si no cuentas con habilidades t\u00e9cnicas. Escalabilidad. Es decir, puedes a\u00f1adir nuevas funcionalidades a tu sitio web en cualquier momento, ya sea a trav\u00e9s de plugins o m\u00f3dulos. Posicionamiento SEO. Puedes posicionar tu sitio web en Google si cuentas con un gestor de contenidos \u201cSEO friendly\u201d, o lo que es lo mismo, que incluya herramientas de optimizaci\u00f3n de contenidos para mejorar tu posici\u00f3n en los motores de b\u00fasqueda. Ahorro econ\u00f3mico. Es mucho m\u00e1s barato desarrollar un sitio web con un CMS que comenzar desde cero, adem\u00e1s de que te ahorras la asistencia t\u00e9cnica si aprendes por ti mismo a solucionar los peque\u00f1os problemas que te vayas encontrando. Seguridad. El servidor de un CMS cuenta con actualizaciones constantes para evitar incidencias de seguridad que afecten a sus usuarios.","title":"\u00bfCu\u00e1les son las ventajas de usar un CMS?"},{"location":"servicios/#cuales-son-las-desventajas-de-usar-un-cms","text":"Requiere mantenerlo siempre actualizado. De lo contrario, su sitio web puede sufrir fallas de seguridad, ideales para los hackers. Tambi\u00e9n puedes sufrir problemas de lentitud en tu sitio, de ah\u00ed la importancia de las actualizaciones. Menos elasticidad. Los CMS de c\u00f3digo abierto suponen una estructura m\u00e1s o menos r\u00edgida, donde podemos hacer lo que queramos siempre que nos atengamos a la configuraci\u00f3n propia de la plataforma. Aprendizaje. Los usuarios deben de aprender nociones m\u00ednimas para administrar su sitio web o de lo contrario requerir\u00e1n pagar personal con experiencia para que el CMS est\u00e9 perfectamente actualizado. Costes adicionales. Ya sea porque quieres mejorar el sitio comprando una plantilla muy original o porque necesitas incrementar funcionalidades que suponen un precio.","title":"\u00bfCu\u00e1les son las desventajas de usar un CMS?"},{"location":"servicios/#por-que-utilizar-django-y-no-un-cms","text":"En primer lugar, son dos cosas distintas. B\u00e1sicamente, WordPress es el tablero a trav\u00e9s del cual organiza el texto y las im\u00e1genes para mostrar en su sitio web. WordPress est\u00e1 construido utilizando el lenguaje de programaci\u00f3n PHP. Django, por otro lado, es lo que se llama un marco web. Basado en el potente lenguaje de programaci\u00f3n Python, es un conjunto de herramientas y bibliotecas que se pueden implementar r\u00e1pidamente para crear aplicaciones web personalizadas. \u00bfCu\u00e1ndo me servir\u00eda wordpress? Cuando desee crear un sitio web basado en una funcionalidad muy explotada y utilizada en el marco del desarrollo web, ya que es muy probable que dicha herramienta tenga incorporado temas y plugins necesarios para implementar en su sitio web. WordPress es una herramienta sencilla y econ\u00f3mica para un sitio b\u00e1sico. Con una gran cantidad de temas gratuitos para descargar, es una forma r\u00e1pida de conectarse y comenzar a promocionar su contenido / negocio / actividad secundaria. Sin embargo, para generar una p\u00e1gina con una funcionalidad original y particular, que se adapte a las necesidades de la aplicaci\u00f3n, estas herramientas (CMS) son menos flexibles, por lo que Django adquiere mucha importancia, proporcionando un marco flexible para implementar soluciones web personalizadas, escalables e innovadoras.","title":"\u00bfPor qu\u00e9 utilizar Django y no un CMS?"},{"location":"servicios/#servicio-a-implementar","text":"Teniendo presentes la finalidad del trabajo y ya justificada la elecci\u00f3n por Django, es que se plantea el siguiente proyecto compuesto por 3 etapas, tal como se ve a continuaci\u00f3n: Esta aplicaci\u00f3n, como se observa en la imagen tiene la finalidad de permitir a cualquier usuario que visite la p\u00e1gina web y mediante una consulta poder visualizar informaci\u00f3n de datos meteorol\u00f3gicos que se encuentran disponibles en las bases de datos y que al mismo tiempo han sido cargados por los diversos sensores con que cuenta la red simulada. Con respecto al acceso a carga de datos al sistema, como se observa a la izquierda, cada uno de los sensores debe de pasar en primera instancia una etapa de registro y/o login para poder alojar su informaci\u00f3n en la base de datos.","title":"Servicio a implementar"},{"location":"servicios/#composicion-del-servicio-django","text":"Para comprender como es que funciona el servicio encargado de generar la p\u00e1gina web, se debe analizar c\u00f3mo se encuentra la carpeta asociada al servicio y que lleva el nombre de \u201cappTrafico\u201d, esta carpeta se puede encontrar dentro del repositorio en la direcci\u00f3n \u201c/Versiones Finales/Proyecto_con_SQlite3/appTrafico\u201d o tambi\u00e9n dentro de \u201c/Versiones Finales/Proyecto_con_PostgreSQL/appTrafico\u201d, su composici\u00f3n es: Para realizar una descripci\u00f3n de la composici\u00f3n de los componentes fundamentales del directorio, primero se debe de observar que al estar trabajando con un esquema dockerizado, se cuenta con un archivo \u201cdockerfile\u201d, este archivo adem\u00e1s de contar con los distintos comandos para poner en funcionamiento Django, necesita de un documento el cual le indica los distintos programas que se necesitan instalar para el total funcionamiento de la aplicaci\u00f3n, en este caso el archivo en cuesti\u00f3n es \u201crequerimientos.txt\u201d. Situado arriba de este archivo, se encuentra \u201cmanage.py\u201d, este script sirve para ejecutar y administrar las herramientas de Django necesarias para este proyecto. Despu\u00e9s se cuenta con 4 carpetas, estas son: \u201dtemplates\u201d ,\u201dstatic\u201d, \u201cregistro\u201d y \u201cconfig\u201d. Templates: Es la carpeta que contiene los html b\u00e1sicos para la aplicaci\u00f3n, en donde uno de sus archivos fundamentales, es \u201cbase.html\u201d, este contiene gran mayor\u00eda de las etiquetas html y que ser\u00e1n heredadas por los distintos html que utilicemos para las ventanas de la p\u00e1gina web. Se podr\u00eda interpretar que es el encargado de dar el esqueleto, donde luego cada pesta\u00f1a sobre esta configuraci\u00f3n b\u00e1sica, agregara el aspecto que sea requerido. Static: Es el directorio encargado de contener los archivos est\u00e1ticos, como son por ejemplo las im\u00e1genes o iconos que se utilizan en la p\u00e1gina web o graficas que son generadas por el servicio y es el directorio de almacenamiento para este contenido Registro: Es el nombre que se le designo a la aplicaci\u00f3n de Django. Que dentro contiene todos los archivos \u201c.py\u201d y \u201c.html\u201d asociados al comportamiento y para la visualizaci\u00f3n de la aplicaci\u00f3n. Su contenido es el siguiente: Dentro de la carpeta \u201ctemplates\u201d es que se encuentran todos los archivos \u201c.html\u201d, luego est\u00e1n todos los scripts necesarios para el funcionamiento de la api. \u201cadmin.py\u201d contiene los modelos que se definir\u00e1n en el proyecto, para este caso se han definido dos, los cuales son \u201csensor\u201d y \u201csensor_dato\u201d. El primero contiene los datos del sensor registrado y \u201csensor_dato\u201d tiene los datos, asociados al clima y ubicaci\u00f3n, que han cargado cada uno de los sensores y que ser\u00e1n los datos que se entregar\u00e1n ante las distintas consultas de los usuarios que accedan a la aplicaci\u00f3n. Estos modelos se encuentran descriptos en \u201cmodels.py\u201d en donde se define los campos que solicita cada uno de ellos para realizar un correcto registro del modelo. \u201cviews.py\u201d contiene la l\u00f3gica de la navegaci\u00f3n por la aplicaci\u00f3n, asociada a las url en \u201curls.py\u201d definidas. Para esta implementaci\u00f3n se han definido 4 urls, los cuales tienen asociados distintos formularios, seg\u00fan los requerimientos y definidos en \u201cforms.py\u201d. Como as\u00ed tambi\u00e9n se direccionar\u00e1 hacia los distintos \u201c.html\u201d ubicados en \u201c/templates\u201d que tiene vinculada cada url. Config: Es la \u00faltima carpeta y contiene todas las configuraciones asociadas al sitio web. Su composici\u00f3n es: El script \u201csettings.py\u201d tiene todas las configuraciones necesarias del sitio, por lo que es donde se registra todas las aplicaciones que se crean, la localizaci\u00f3n de los ficheros est\u00e1ticos, los detalles de configuraci\u00f3n de la base de datos, etc. \u201curls.py\u201d define los mapeos url-vistas. A pesar de que \u00e9ste podr\u00eda contener todo el c\u00f3digo del mapeo url, es m\u00e1s com\u00fan repartir parte del mapeo a las propias aplicaciones, como sucedi\u00f3 en \u201c/registro\u201d. \u201cwsgi.py\u201d y \u201casgi.py\u201d se utilizan para ayudar a la aplicaci\u00f3n Django a comunicarse con el servidor web. De todos estos scripts, el m\u00e1s importante a describir es \u201csettings.py\u201d, en el cual algunas de las configuraciones m\u00e1s importantes son: BASE_DIR: Es la variable que tiene como contenido la ruta a una determinada ubicaci\u00f3n del proyecto, en este caso esta direccionado hacia la ubicaci\u00f3n del settings.py SECRET_KEY: Es la contrase\u00f1a asociada con el proyecto Django DEBUG: Es una variable booleana, que debe configurarse en True mientras el proyecto est\u00e9 en desarrollo, para poder ver los posibles errores por parte de Django. En caso de llevar el proyecto a producci\u00f3n, el estado de esta variable debe configurarse en False. ALLOWED_HOSTS: Asigna los host que pueden acceder al proyecto, esta variable debe de estar bien configurada para poder hacer acceso a la aplicaci\u00f3n desde otros host INSTALLED_APPS: Es en donde se establecen las aplicaciones propias y de terceros que se van a utilizar, como es el caso del debug implementado para Django o la recolecci\u00f3n de m\u00e9tricas hacia InfluxDB MIDDLEWARE: Es un sub framework que permite modificaciones al sistema de procesamiento de request/response de Django, en donde cada componente middleware es responsable de hacer alguna funci\u00f3n espec\u00edfica y suele estar acompa\u00f1ado con las aplicaciones que se agregan en \u201cINSTALLED_APPS\u201d TEMPLATES: Se describe al proyecto en donde debe de buscar las plantillas para implementar en la aplicaci\u00f3n DATABASES: Es la variable de configuraci\u00f3n asociada a la base de datos a implementar, en este caso en particular se podr\u00e1 ver configurado SQlite 3 o PostgreSQL seg\u00fan sea el caso. DEBUG_TOOLBAR_PANELS: Son las configuraciones para los distintos datos que nos entregara el debug a\u00f1adido como aplicaci\u00f3n en \u201cINSTALLED_APPS\u201d y que se visualizaran al navegar por la p\u00e1gina web INFLUXDB_: Son las distintas configuraciones necesarias para que las m\u00e9tricas obtenidas en Django sean llevadas hacia InfluxDB, nuevamente estas configuraciones est\u00e1n asociadas con la aplicaci\u00f3n a\u00f1adida en \u201cINSTALLED_APPS\u201d","title":"Composici\u00f3n del Servicio Django"},{"location":"servicios/#navegacion-por-el-servicio-django","text":"Para poder entender la navegaci\u00f3n dentro de la aplicaci\u00f3n, es que se presenta un diagrama de flujo el cual contiene todas las pestanas asociadas a la p\u00e1gina web y que dan sentido a la implementaci\u00f3n de todas las configuraciones antes mencionadas. Para comprender el funcionamiento de la navegaci\u00f3n es que se debe tener presente que la aplicaci\u00f3n podr\u00e1 ser consultada por 2 grupos diferenciados, siendo estos Sensores y Usuarios, los cuales experimentaran una navegaci\u00f3n diferente. Una vez mencionado este detalle, el diagrama de flujo es: Para acceder a la pagina web se debe ingresar la direcci\u00f3n: http://127.0.0.1:8010 o http://172.2x.0.2:8010 en el caso de estar accediendo desde el mismo host, en caso de acceder de manera externa, se debe de acceder mediante el ip que tiene asignado el host que contiene el servicio y redireccionar hacia el puerto 8010, tal como se hizo en las dos direcciones anteriores. Una vez que se ha accedido a la p\u00e1gina se podr\u00e1 ver un panel superior desplegable, el cual nos puede llevar a el mismo home en el cual nos encontramos, a realizar un registro de un nuevo sensor o una carga de datos por parte de los sensores. En la parte central de la p\u00e1gina est\u00e1n los botones asociados a \u201ciniciar sesi\u00f3n\u201d o \u201cconsultar datos\u201d es en esta instancia que la navegaci\u00f3n por la p\u00e1gina web bifurca seg\u00fan sea el caso de un sensor que inicie sesi\u00f3n o un usuario que consulte datos climatol\u00f3gicos. Considerando el caso de este \u00faltimo, se lo llevar\u00e1 hacia una nueva url asociada a \u201c/registro/procUser\u201d en donde el usuario mediante el correcto llenado de un formulario que solicita la ubicaci\u00f3n y caracter\u00edsticas climatol\u00f3gicas, podr\u00e1 visualizar los datos solicitados a la base de datos y, si as\u00ed lo desea, realizar nuevas consultas mediante la variaci\u00f3n en el formulario antes comentado. Con respecto a los sensores y en la otra rama de navegaci\u00f3n, estos deber\u00e1n iniciar sesi\u00f3n en donde ser\u00e1n llevados a \u201c/accounts/login\u201d, si se diera el caso de que el sensor no este registrado, debe de ingresar a \u201c/registro/nuevo\u201d para un posterior login. Una vez que el sensor ha iniciado sesi\u00f3n correctamente, es que podr\u00e1 acceder a \u201c/registro/privado\u201d para poder cargar los datos asociados a su ubicaci\u00f3n geogr\u00e1fica y los datos climatol\u00f3gicos obtenidos, estos datos ser\u00e1n cargados mediante un formulario, que en el caso de estar ingresados de manera correcta ser\u00e1n registrados en la base de datos. Luego el sensor podr\u00e1 ver sus \u00faltimos registros cargados visualiz\u00e1ndose mediante una tabla y distintas gr\u00e1ficas.","title":"Navegaci\u00f3n por el servicio Django"},{"location":"servicios/#fuente-de-informacion","text":"https://openwebinars.net/blog/que-es-django-y-por-que-usarlo/ https://devcode.la/blog/por-que-usar-django/ https://www.azulschool.net/que-es-django-y-para-que-sirve/ https://platzi.com/blog/django-el-framework-para-desarrollo-web/ https://codingornot.com/django-por-que-usar-django https://www.djangosites.org/ https://djangopackages.org/ https://www.opensourcecms.com/ https://www.comparahosting.com/que-es-un-cms-y-para-que-sirve/ https://elbauldelprogramador.com/los-10-mejores-frameworks-gratis-de-aplicaciones-web/ https://www.django-cms.org/en/why-django-cms/ https://uniwebsidad.com/libros/django-1-0/capitulo-5/el-patron-de-diseno-mtv https://medium.com/infeenix/django-vs-wordpress-c%C3%B3mo-me-decido-97442a76c8d2","title":"Fuente de Informacion"},{"location":"visualizacionDeMetricas/","text":"Visualizaci\u00f3n de m\u00e9tricas \u00bf Qu\u00e9 es grafana ? Grafana es una herramienta para visualizar datos de serie temporales. A partir de una serie de datos recolectados se obtiene un panorama gr\u00e1fico de la situaci\u00f3n muy simple de interpretar y visualizar, se utiliza para el monitoreo de infraestructura de IT, mediciones de aplicaciones, control de procesos, sensores industriales, automatizaci\u00f3n de hogares y medici\u00f3n del clima entre otros usos. El objetivo de Grafana es presentar los datos de monitoreo de una manera m\u00e1s f\u00e1cil de usar y agradable, recolectada y/o procesada por aplicaciones de terceros, aunque puede recopilar de forma nativa datos de Cloudwatch, Graphite, Elasticsearch, OpenTSDB, Prometheus, Hosted Metrics e InfluxDB. Tambien existe una versi\u00f3n Enterprise de Grafana (grafana.com) que usa complementos para otras fuentes de datos y ofrece soporte 24\u00d77, pero en general estos complementos de fuentes de datos pueden crearse de fuente abierta. Como editor de m\u00e9tricas flexible, ofrece la posibilidad de crear paneles de control gen\u00e9ricos que se pueden cambiar r\u00e1pidamente para mostrar diferentes estad\u00edsticas de un cluster, servidor o aplicaciones espec\u00edficas. Gracias a su rapidez y flexibilidad, los nombres de grupo, hosts, aplicaciones o nombres de elementos pueden ser reemplazados con solamente cambiar una variable dentro de la plantilla. Grafana asimismo facilita la obtenci\u00f3n de los datos a partir de docenas de bases de datos, de forma nativa, y que pueden ser mezcladas f\u00e1cilmente en el mismo tablero. Un tablero o dashboard de Grafana es una vista que contiene m\u00faltiples gr\u00e1ficos y paneles individuales organizados en forma de grilla. Los dashboards son el concepto clave detr\u00e1s de Grafana, pues son el medio a trav\u00e9s del cual se logra simplificar y agrupar m\u00e9tricas en una vista simple y amigable con el objetivo de mejorar la comprensi\u00f3n sobre los datos e informaci\u00f3n disponible. Tambi\u00e9n es posible definir reglas de alertas de forma visual para las m\u00e9tricas m\u00e1s importantes. Grafana eval\u00faa estas reglas de forma permanente y continua y env\u00eda notificaciones en diferentes formas. \u00bfC\u00f3mo crear un dashboard en Grafana? Despu\u00e9s de instalar Grafana, accederemos a su interfaz web para empezar con la creaci\u00f3n de los dashboards. Una vez hagamos login tendremos que configurar un Data Source, que ser\u00e1 desde donde Grafana obtenga los datos de las m\u00e9tricas. De este modo, podremos crear un dashboard presionando el bot\u00f3n New dashboard. Para el caso de nuestra infraestructura de red, tenemos que realizar la siguiente configuraci\u00f3n: Lo que indica a Grafana que la fuente de datos se encuentra http://172.21.0.4:8086 y corresponde una base de datos de InfluxDB. \u00bfQu\u00e9 es InfluxDB? InfluxDB es un sistema de gesti\u00f3n de bases de datos desarrollado por la empresa InfluxData, Inc. como software de c\u00f3digo abierto, por lo que puede ser utilizado de forma gratuita. Sin embargo existe una versi\u00f3n comercial que proporciona algunos servicios adicionales. InfluxDB ha sido concebido para bases de datos de time series (TSDB), que almacenan series temporales. Estas bases de datos se usan, entre otras cosas, para almacenar y evaluar datos de sensores o protocolos con marcas temporales durante un per\u00edodo de tiempo determinado. En estos casos es posible que entren millones de juegos de datos, como los que proporcionan los equipos del Internet de las cosas o los instrumentos cient\u00edficos de medici\u00f3n a trav\u00e9s de un flujo continuo de datos. Este tipo de datos deben procesarse r\u00e1pidamente en cuanto llegan a la base de datos. Por ello, InfluxDB cuenta con un servicio de tiempo que usa el Network Time Protocol (NTP) para garantizar que el tiempo est\u00e1 sincronizado en todos los sistemas. Las bases de datos de InfluxDB suelen ser muy compactas y solo necesitan contar con dos o tres columnas. En ellas se guarda, por ejemplo, la fuente de los datos, el valor en s\u00ed y la marca temporal correspondiente. InfluxDB distingue entre tags y fields. Mientras que los tags solo contienen metadatos incluidos en el \u00edndice, los fields incluyen valores que pueden evaluarse m\u00e1s adelante. Por lo tanto, en nuestro ejemplo, la primera columna es una tag y la segunda, un field. Esta distinci\u00f3n facilita el manejo de la base de datos y la evaluaci\u00f3n de los datos de medici\u00f3n. \u00bfDonde observamos los datos de nuestra base de datos influxDB en forma de tabla ? En Chronograf . Este servicio es la interfaz de usuario y el componente administrativo de la plataforma InfluxDB 1.x. Como herramienta, ademas de visualizar la estructura de la base de datos, trae integrada diferentes plantillas y bibliotecas para crear cuadros de mando r\u00e1pidamente con visualizaciones en tiempo real. Muy parecido a Grafana. Chronograf permite ver r\u00e1pidamente los datos que se han almacenado en InfluxDB para que pueda generar consultas y alertas s\u00f3lidas. De esta forma, al conocer la manera que est\u00e1 estructurada la base de datos, resulta m\u00e1s sencillo realizar consultas desde Grafana. \u00bfCu\u00e1les son las ventajas de InfluxDB? Las TSDB como InfluxDB son mucho m\u00e1s r\u00e1pidas que las bases de datos relacionales a la hora de almacenar y procesar datos de medici\u00f3n con marcas temporales. Un sistema de gesti\u00f3n de bases de datos (DBMS) dedica parte de su rendimiento a la organizaci\u00f3n de un \u00edndice complejo, que en este \u00e1mbito de aplicaci\u00f3n no se usa. InfluxDB tambi\u00e9n es capaz de mantener una elevada velocidad de escritura, ya que usa un \u00edndice muy sencillo. Monitoreo de Postgres Para el monitoreo y visualizacion de metricas referidas a postgres es necesario incluir otra fuente de datos influxdb definida como telegraf . Esta ultima, esta junto a la base de datos de influx donde se almacenan metricas de Django, Locust y Cadvisor. La unica diferencia es que la base de datos telegraf solo recibe metricas de un unico agente (contenedor telegraf) dedicado puramente y exclusivamente al monitoreo de postgres. Inclusi\u00f3n de link para reporte a PDF y apitoken Con la finalidad de poder obtener los reportes de las distintas simulaciones realizadas y que se deseen realizar, es que al esquema dockerizado se le ha incorporado el servicio \u201creporter\u201d con el \u00fanico sentido de poder obtener y guardar mediante un PDF los dashboard de Grafana. Para poder obtener estos reportes, es que se debe realizar una configuraci\u00f3n adicional sobre los dashboard que est\u00e9n creados. En Settings, se debe ir hasta \u201cLinks\u201d y luego completar los campos de la siguiente manera: En el campo de URL se debe ingresar la IP asignada al servicio \u201creporter\u201d seguido de \u201c/api/report\u201d y luego el nombre del dashboard tal como figura en el navegador, en este ejemplo en particular era \u201cpostgres-overview\u201d. Quedando esta url de la siguiente manera: http://172.20.0.10:8686/api/report/postgres-overview?apitoken= clave apitoken = Esto nos a\u00f1ade en la esquina superior derecha del dashboard un bot\u00f3n el cual nos redireccionar\u00e1 en una nueva pestana a realizar el reporte en PDF Si se presta atenci\u00f3n a la direcci\u00f3n antes presentada, se puede observar que seguido al nombre del dashboard se encuentra la palabra \u201capitoken\u201d acompa\u00f1ado de su clave. Este es un argumento fundamental y el cual nos permite limitar el acceso o visibilidad de los dashboard. Como para acceder a Grafana se ha configurado un usuario y contrase\u00f1a, para poder exportar los dashboard a otros servicios, es necesario que se cuente con un \u201capitoken\u201d o \u201capikey\u201d el cual da los permisos para que los servicios tengan acceso a los dashboard. Para poder obtener esta clave es que en la esquina superior izquierda, sobre el icono de Grafana, se debe de clickear y dirigir a Admin -> Apikey. Una vez que se est\u00e1 en la pesta\u00f1a de API Keys, se debe asignar un nombre a la key y clickear en Add, esto nos abrir\u00e1 una ventana con el c\u00f3digo que se mostrar\u00e1 por \u00fanica vez. El pr\u00f3ximo paso es copiar la key y se debe pegar en la url del link para poder generar el reporte. De esta manera el servicio \u201creporter\u201d tendr\u00e1 acceso al dashboard y podr\u00e1 realizar el PDF con los par\u00e1metros configurados en el dashboard.","title":"Visualizaci\u00f3n de m\u00e9tricas"},{"location":"visualizacionDeMetricas/#visualizacion-de-metricas","text":"","title":"Visualizaci\u00f3n de m\u00e9tricas"},{"location":"visualizacionDeMetricas/#que-es-grafana","text":"Grafana es una herramienta para visualizar datos de serie temporales. A partir de una serie de datos recolectados se obtiene un panorama gr\u00e1fico de la situaci\u00f3n muy simple de interpretar y visualizar, se utiliza para el monitoreo de infraestructura de IT, mediciones de aplicaciones, control de procesos, sensores industriales, automatizaci\u00f3n de hogares y medici\u00f3n del clima entre otros usos. El objetivo de Grafana es presentar los datos de monitoreo de una manera m\u00e1s f\u00e1cil de usar y agradable, recolectada y/o procesada por aplicaciones de terceros, aunque puede recopilar de forma nativa datos de Cloudwatch, Graphite, Elasticsearch, OpenTSDB, Prometheus, Hosted Metrics e InfluxDB. Tambien existe una versi\u00f3n Enterprise de Grafana (grafana.com) que usa complementos para otras fuentes de datos y ofrece soporte 24\u00d77, pero en general estos complementos de fuentes de datos pueden crearse de fuente abierta. Como editor de m\u00e9tricas flexible, ofrece la posibilidad de crear paneles de control gen\u00e9ricos que se pueden cambiar r\u00e1pidamente para mostrar diferentes estad\u00edsticas de un cluster, servidor o aplicaciones espec\u00edficas. Gracias a su rapidez y flexibilidad, los nombres de grupo, hosts, aplicaciones o nombres de elementos pueden ser reemplazados con solamente cambiar una variable dentro de la plantilla. Grafana asimismo facilita la obtenci\u00f3n de los datos a partir de docenas de bases de datos, de forma nativa, y que pueden ser mezcladas f\u00e1cilmente en el mismo tablero. Un tablero o dashboard de Grafana es una vista que contiene m\u00faltiples gr\u00e1ficos y paneles individuales organizados en forma de grilla. Los dashboards son el concepto clave detr\u00e1s de Grafana, pues son el medio a trav\u00e9s del cual se logra simplificar y agrupar m\u00e9tricas en una vista simple y amigable con el objetivo de mejorar la comprensi\u00f3n sobre los datos e informaci\u00f3n disponible. Tambi\u00e9n es posible definir reglas de alertas de forma visual para las m\u00e9tricas m\u00e1s importantes. Grafana eval\u00faa estas reglas de forma permanente y continua y env\u00eda notificaciones en diferentes formas.","title":"\u00bf Qu\u00e9 es grafana ?"},{"location":"visualizacionDeMetricas/#como-crear-un-dashboard-en-grafana","text":"Despu\u00e9s de instalar Grafana, accederemos a su interfaz web para empezar con la creaci\u00f3n de los dashboards. Una vez hagamos login tendremos que configurar un Data Source, que ser\u00e1 desde donde Grafana obtenga los datos de las m\u00e9tricas. De este modo, podremos crear un dashboard presionando el bot\u00f3n New dashboard. Para el caso de nuestra infraestructura de red, tenemos que realizar la siguiente configuraci\u00f3n: Lo que indica a Grafana que la fuente de datos se encuentra http://172.21.0.4:8086 y corresponde una base de datos de InfluxDB.","title":"\u00bfC\u00f3mo crear un dashboard en Grafana?"},{"location":"visualizacionDeMetricas/#que-es-influxdb","text":"InfluxDB es un sistema de gesti\u00f3n de bases de datos desarrollado por la empresa InfluxData, Inc. como software de c\u00f3digo abierto, por lo que puede ser utilizado de forma gratuita. Sin embargo existe una versi\u00f3n comercial que proporciona algunos servicios adicionales. InfluxDB ha sido concebido para bases de datos de time series (TSDB), que almacenan series temporales. Estas bases de datos se usan, entre otras cosas, para almacenar y evaluar datos de sensores o protocolos con marcas temporales durante un per\u00edodo de tiempo determinado. En estos casos es posible que entren millones de juegos de datos, como los que proporcionan los equipos del Internet de las cosas o los instrumentos cient\u00edficos de medici\u00f3n a trav\u00e9s de un flujo continuo de datos. Este tipo de datos deben procesarse r\u00e1pidamente en cuanto llegan a la base de datos. Por ello, InfluxDB cuenta con un servicio de tiempo que usa el Network Time Protocol (NTP) para garantizar que el tiempo est\u00e1 sincronizado en todos los sistemas. Las bases de datos de InfluxDB suelen ser muy compactas y solo necesitan contar con dos o tres columnas. En ellas se guarda, por ejemplo, la fuente de los datos, el valor en s\u00ed y la marca temporal correspondiente. InfluxDB distingue entre tags y fields. Mientras que los tags solo contienen metadatos incluidos en el \u00edndice, los fields incluyen valores que pueden evaluarse m\u00e1s adelante. Por lo tanto, en nuestro ejemplo, la primera columna es una tag y la segunda, un field. Esta distinci\u00f3n facilita el manejo de la base de datos y la evaluaci\u00f3n de los datos de medici\u00f3n.","title":"\u00bfQu\u00e9 es InfluxDB?"},{"location":"visualizacionDeMetricas/#cuales-son-las-ventajas-de-influxdb","text":"Las TSDB como InfluxDB son mucho m\u00e1s r\u00e1pidas que las bases de datos relacionales a la hora de almacenar y procesar datos de medici\u00f3n con marcas temporales. Un sistema de gesti\u00f3n de bases de datos (DBMS) dedica parte de su rendimiento a la organizaci\u00f3n de un \u00edndice complejo, que en este \u00e1mbito de aplicaci\u00f3n no se usa. InfluxDB tambi\u00e9n es capaz de mantener una elevada velocidad de escritura, ya que usa un \u00edndice muy sencillo.","title":"\u00bfCu\u00e1les son las ventajas de InfluxDB?"},{"location":"visualizacionDeMetricas/#monitoreo-de-postgres","text":"Para el monitoreo y visualizacion de metricas referidas a postgres es necesario incluir otra fuente de datos influxdb definida como telegraf . Esta ultima, esta junto a la base de datos de influx donde se almacenan metricas de Django, Locust y Cadvisor. La unica diferencia es que la base de datos telegraf solo recibe metricas de un unico agente (contenedor telegraf) dedicado puramente y exclusivamente al monitoreo de postgres.","title":"Monitoreo de Postgres"},{"location":"visualizacionDeMetricas/#inclusion-de-link-para-reporte-a-pdf-y-apitoken","text":"Con la finalidad de poder obtener los reportes de las distintas simulaciones realizadas y que se deseen realizar, es que al esquema dockerizado se le ha incorporado el servicio \u201creporter\u201d con el \u00fanico sentido de poder obtener y guardar mediante un PDF los dashboard de Grafana. Para poder obtener estos reportes, es que se debe realizar una configuraci\u00f3n adicional sobre los dashboard que est\u00e9n creados. En Settings, se debe ir hasta \u201cLinks\u201d y luego completar los campos de la siguiente manera: En el campo de URL se debe ingresar la IP asignada al servicio \u201creporter\u201d seguido de \u201c/api/report\u201d y luego el nombre del dashboard tal como figura en el navegador, en este ejemplo en particular era \u201cpostgres-overview\u201d. Quedando esta url de la siguiente manera: http://172.20.0.10:8686/api/report/postgres-overview?apitoken= clave apitoken = Esto nos a\u00f1ade en la esquina superior derecha del dashboard un bot\u00f3n el cual nos redireccionar\u00e1 en una nueva pestana a realizar el reporte en PDF Si se presta atenci\u00f3n a la direcci\u00f3n antes presentada, se puede observar que seguido al nombre del dashboard se encuentra la palabra \u201capitoken\u201d acompa\u00f1ado de su clave. Este es un argumento fundamental y el cual nos permite limitar el acceso o visibilidad de los dashboard. Como para acceder a Grafana se ha configurado un usuario y contrase\u00f1a, para poder exportar los dashboard a otros servicios, es necesario que se cuente con un \u201capitoken\u201d o \u201capikey\u201d el cual da los permisos para que los servicios tengan acceso a los dashboard. Para poder obtener esta clave es que en la esquina superior izquierda, sobre el icono de Grafana, se debe de clickear y dirigir a Admin -> Apikey. Una vez que se est\u00e1 en la pesta\u00f1a de API Keys, se debe asignar un nombre a la key y clickear en Add, esto nos abrir\u00e1 una ventana con el c\u00f3digo que se mostrar\u00e1 por \u00fanica vez. El pr\u00f3ximo paso es copiar la key y se debe pegar en la url del link para poder generar el reporte. De esta manera el servicio \u201creporter\u201d tendr\u00e1 acceso al dashboard y podr\u00e1 realizar el PDF con los par\u00e1metros configurados en el dashboard.","title":"Inclusi\u00f3n de link para reporte a PDF y apitoken"}]}